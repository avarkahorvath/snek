{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Library imports, setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you change a file, you dont have to restart the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 23:56:54.733091: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-03 23:56:54.778360: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-03 23:56:56.109750: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from data import load_metadata, visualize_data, make_dataset\n",
    "from model import build_multitask_model\n",
    "from score_metrics import get_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7956,
     "status": "ok",
     "timestamp": 1760103668680,
     "user": {
      "displayName": "Avarka",
      "userId": "01376155912533068519"
     },
     "user_tz": -120
    },
    "id": "cb7d91df",
    "outputId": "632fa06d-510c-411c-bd31-1a43c8eb8343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n",
      "Found GPU /physical_device:GPU:0, and set memory growth to True.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check tf version\n",
    "print(tf.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for device in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "    print(f\"Found GPU {device.name}, and set memory growth to True.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Egyetem_adat/kigyo2/snek/src/Models/data.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  image_metadata[\"encoded_id\"] = encoder.fit_transform(image_metadata[\"class_id\"])\n",
      "/mnt/d/Egyetem_adat/kigyo2/snek/src/Models/data.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  image_metadata[\"image_path\"] = image_metadata[\"image_path\"].apply(\n"
     ]
    }
   ],
   "source": [
    "image_metadata, species_metadata = load_metadata()\n",
    "NUM_SPECIES = len(species_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in data.py\n",
    "#visualize_data(image_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "d98e31d7"
   },
   "source": [
    "Loading python images from folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_multitask_model\n",
    "from score_metrics import get_scores\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "IMAGE_RESOLUTION=224\n",
    "#IMAGE_RESOLUTION=544\n",
    "\n",
    "\n",
    "NUM_FOLDS = 3\n",
    "\n",
    "from data import make_batches\n",
    "\n",
    "\n",
    "\n",
    "X_paths = image_metadata[\"image_path\"].values\n",
    "y_species = image_metadata[\"encoded_id\"].values\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "\n",
    "best_fold_idx = None\n",
    "best_macro_f1 = -np.inf\n",
    "\n",
    "all_y_species_true = []\n",
    "all_y_species_pred = []\n",
    "all_y_venom_true = []\n",
    "all_y_venom_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764802617.230368    8591 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 1/3 =====\n",
      "\n",
      "===== FOLD 2/3 =====\n",
      "\n",
      "===== FOLD 3/3 =====\n"
     ]
    }
   ],
   "source": [
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_paths, y_species), start=1):\n",
    "    print(f\"\\n===== FOLD {fold_idx}/{NUM_FOLDS} =====\")\n",
    "\n",
    "    train_info = image_metadata.iloc[train_idx].copy()\n",
    "    val_info   = image_metadata.iloc[val_idx].copy()\n",
    "\n",
    "    # --- class weight csak a trainre számolva ---\n",
    "    species_classes = np.unique(train_info[\"encoded_id\"])\n",
    "    species_cw = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=species_classes,\n",
    "        y=train_info[\"encoded_id\"],\n",
    "    )\n",
    "    species_cw_dict = {int(c): w for c, w in zip(species_classes, species_cw)}\n",
    "\n",
    "    species_weight_vec = tf.constant(\n",
    "        [species_cw_dict[i] for i in range(len(species_cw_dict))],\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "\n",
    "    # --- tf.data datasetek ---\n",
    "    train_dataset = make_batches(\n",
    "        train_info,\n",
    "        IMAGE_RESOLUTION,\n",
    "        species_weight_vec=species_weight_vec,\n",
    "    )\n",
    "    val_dataset = make_batches(\n",
    "        val_info,\n",
    "        IMAGE_RESOLUTION,\n",
    "        species_weight_vec=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 1/3 =====\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 23:57:05.862735: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 261/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 90ms/step - loss: 5.9622 - species_accuracy: 0.0136 - species_loss: 5.7180 - venom_accuracy: 0.7926 - venom_loss: 0.4883"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 632/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 88ms/step - loss: 5.7603 - species_accuracy: 0.0230 - species_loss: 5.5249 - venom_accuracy: 0.8012 - venom_loss: 0.4708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 23:58:01.875648: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5.4930 - species_accuracy: 0.0373 - species_loss: 5.2633 - venom_accuracy: 0.8056 - venom_loss: 0.4593\n",
      "Epoch 1: val_loss improved from None to 4.36281, saving model to best_model_fold1.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 139ms/step - loss: 5.1137 - species_accuracy: 0.0591 - species_loss: 4.8894 - venom_accuracy: 0.8091 - venom_loss: 0.4474 - val_loss: 4.3628 - val_species_accuracy: 0.1198 - val_species_loss: 4.1608 - val_venom_accuracy: 0.8252 - val_venom_loss: 0.4056 - learning_rate: 5.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m 496/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 90ms/step - loss: 4.4066 - species_accuracy: 0.1171 - species_loss: 4.1951 - venom_accuracy: 0.8200 - venom_loss: 0.4231"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:01:03.305443: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 595/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 89ms/step - loss: 4.4074 - species_accuracy: 0.1169 - species_loss: 4.1952 - venom_accuracy: 0.8189 - venom_loss: 0.4245"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4.3798 - species_accuracy: 0.1182 - species_loss: 4.1666 - venom_accuracy: 0.8167 - venom_loss: 0.4264\n",
      "Epoch 2: val_loss improved from 4.36281 to 4.14929, saving model to best_model_fold1.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 138ms/step - loss: 4.3299 - species_accuracy: 0.1220 - species_loss: 4.1170 - venom_accuracy: 0.8161 - venom_loss: 0.4256 - val_loss: 4.1493 - val_species_accuracy: 0.1528 - val_species_loss: 3.9486 - val_venom_accuracy: 0.8280 - val_venom_loss: 0.4001 - learning_rate: 5.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m  45/1385\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 87ms/step - loss: 3.9857 - species_accuracy: 0.1545 - species_loss: 3.7731 - venom_accuracy: 0.8096 - venom_loss: 0.4252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 333/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 97ms/step - loss: 3.9548 - species_accuracy: 0.1586 - species_loss: 3.7438 - venom_accuracy: 0.8164 - venom_loss: 0.4220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:04:01.472080: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 3.9910 - species_accuracy: 0.1574 - species_loss: 3.7810 - venom_accuracy: 0.8178 - venom_loss: 0.4200\n",
      "Epoch 3: val_loss improved from 4.14929 to 4.00243, saving model to best_model_fold1.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 145ms/step - loss: 4.0092 - species_accuracy: 0.1576 - species_loss: 3.8007 - venom_accuracy: 0.8189 - venom_loss: 0.4176 - val_loss: 4.0024 - val_species_accuracy: 0.1748 - val_species_loss: 3.8045 - val_venom_accuracy: 0.8302 - val_venom_loss: 0.3940 - learning_rate: 5.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m  38/1385\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 86ms/step - loss: 3.9634 - species_accuracy: 0.1727 - species_loss: 3.7398 - venom_accuracy: 0.8031 - venom_loss: 0.4472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 991/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 92ms/step - loss: 3.7737 - species_accuracy: 0.1844 - species_loss: 3.5640 - venom_accuracy: 0.8187 - venom_loss: 0.4194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:08:22.235902: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 3.7759 - species_accuracy: 0.1846 - species_loss: 3.5666 - venom_accuracy: 0.8192 - venom_loss: 0.4185\n",
      "Epoch 4: val_loss improved from 4.00243 to 3.97183, saving model to best_model_fold1.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 141ms/step - loss: 3.7904 - species_accuracy: 0.1839 - species_loss: 3.5824 - venom_accuracy: 0.8215 - venom_loss: 0.4145 - val_loss: 3.9718 - val_species_accuracy: 0.1824 - val_species_loss: 3.7743 - val_venom_accuracy: 0.8300 - val_venom_loss: 0.3941 - learning_rate: 5.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m 198/1385\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 102ms/step - loss: 3.5409 - species_accuracy: 0.2183 - species_loss: 3.3424 - venom_accuracy: 0.8262 - venom_loss: 0.3969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 803/1385\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 94ms/step - loss: 3.5860 - species_accuracy: 0.2131 - species_loss: 3.3826 - venom_accuracy: 0.8216 - venom_loss: 0.4066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:11:21.663394: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 3.5960 - species_accuracy: 0.2110 - species_loss: 3.3920 - venom_accuracy: 0.8211 - venom_loss: 0.4080\n",
      "Epoch 5: val_loss improved from 3.97183 to 3.91812, saving model to best_model_fold1.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 144ms/step - loss: 3.6157 - species_accuracy: 0.2067 - species_loss: 3.4110 - venom_accuracy: 0.8206 - venom_loss: 0.4093 - val_loss: 3.9181 - val_species_accuracy: 0.1916 - val_species_loss: 3.7224 - val_venom_accuracy: 0.8308 - val_venom_loss: 0.3931 - learning_rate: 5.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m 840/1385\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 93ms/step - loss: 3.3921 - species_accuracy: 0.2334 - species_loss: 3.1896 - venom_accuracy: 0.8210 - venom_loss: 0.4050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 913/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 93ms/step - loss: 3.3946 - species_accuracy: 0.2333 - species_loss: 3.1922 - venom_accuracy: 0.8213 - venom_loss: 0.4048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:14:50.240601: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 3.4104 - species_accuracy: 0.2320 - species_loss: 3.2078 - venom_accuracy: 0.8220 - venom_loss: 0.4052\n",
      "Epoch 6: val_loss improved from 3.91812 to 3.90487, saving model to best_model_fold1.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 136ms/step - loss: 3.4578 - species_accuracy: 0.2269 - species_loss: 3.2549 - venom_accuracy: 0.8227 - venom_loss: 0.4063 - val_loss: 3.9049 - val_species_accuracy: 0.1967 - val_species_loss: 3.7077 - val_venom_accuracy: 0.8290 - val_venom_loss: 0.3941 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m 226/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 96ms/step - loss: 3.2027 - species_accuracy: 0.2526 - species_loss: 2.9976 - venom_accuracy: 0.8171 - venom_loss: 0.4102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:16:55.748911: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 975/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 90ms/step - loss: 3.2671 - species_accuracy: 0.2498 - species_loss: 3.0639 - venom_accuracy: 0.8221 - venom_loss: 0.4064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 3.2856 - species_accuracy: 0.2481 - species_loss: 3.0825 - venom_accuracy: 0.8224 - venom_loss: 0.4063\n",
      "Epoch 7: val_loss did not improve from 3.90487\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 139ms/step - loss: 3.3371 - species_accuracy: 0.2423 - species_loss: 3.1339 - venom_accuracy: 0.8235 - venom_loss: 0.4057 - val_loss: 3.9133 - val_species_accuracy: 0.1953 - val_species_loss: 3.7173 - val_venom_accuracy: 0.8325 - val_venom_loss: 0.3918 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m 445/1385\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 101ms/step - loss: 3.1969 - species_accuracy: 0.2624 - species_loss: 2.9967 - venom_accuracy: 0.8251 - venom_loss: 0.4004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:20:32.184707: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 986/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 96ms/step - loss: 3.1920 - species_accuracy: 0.2635 - species_loss: 2.9913 - venom_accuracy: 0.8252 - venom_loss: 0.4013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 3.1980 - species_accuracy: 0.2626 - species_loss: 2.9973 - venom_accuracy: 0.8249 - venom_loss: 0.4015\n",
      "Epoch 8: val_loss improved from 3.90487 to 3.88761, saving model to best_model_fold1.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 140ms/step - loss: 3.2233 - species_accuracy: 0.2593 - species_loss: 3.0221 - venom_accuracy: 0.8239 - venom_loss: 0.4026 - val_loss: 3.8876 - val_species_accuracy: 0.2050 - val_species_loss: 3.6906 - val_venom_accuracy: 0.8303 - val_venom_loss: 0.3948 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m 294/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 94ms/step - loss: 2.9760 - species_accuracy: 0.2837 - species_loss: 2.7817 - venom_accuracy: 0.8329 - venom_loss: 0.3886"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:23:29.651840: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 933/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 88ms/step - loss: 3.0323 - species_accuracy: 0.2819 - species_loss: 2.8351 - venom_accuracy: 0.8294 - venom_loss: 0.3944"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 3.0575 - species_accuracy: 0.2794 - species_loss: 2.8592 - venom_accuracy: 0.8279 - venom_loss: 0.3966\n",
      "Epoch 9: val_loss did not improve from 3.88761\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 3.1197 - species_accuracy: 0.2716 - species_loss: 2.9191 - venom_accuracy: 0.8244 - venom_loss: 0.4011 - val_loss: 3.9009 - val_species_accuracy: 0.2064 - val_species_loss: 3.7045 - val_venom_accuracy: 0.8333 - val_venom_loss: 0.3897 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m 335/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 93ms/step - loss: 2.9219 - species_accuracy: 0.2960 - species_loss: 2.7223 - venom_accuracy: 0.8241 - venom_loss: 0.3992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 428/1385\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 90ms/step - loss: 2.9259 - species_accuracy: 0.2949 - species_loss: 2.7271 - venom_accuracy: 0.8247 - venom_loss: 0.3976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:26:47.603793: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.9682 - species_accuracy: 0.2895 - species_loss: 2.7699 - venom_accuracy: 0.8255 - venom_loss: 0.3965\n",
      "Epoch 10: val_loss did not improve from 3.88761\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 140ms/step - loss: 3.0159 - species_accuracy: 0.2845 - species_loss: 2.8171 - venom_accuracy: 0.8262 - venom_loss: 0.3972 - val_loss: 3.9409 - val_species_accuracy: 0.2044 - val_species_loss: 3.7447 - val_venom_accuracy: 0.8345 - val_venom_loss: 0.3913 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m  53/1385\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:25\u001b[0m 154ms/step - loss: 2.6664 - species_accuracy: 0.3369 - species_loss: 2.4788 - venom_accuracy: 0.8422 - venom_loss: 0.3752"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 206/1385\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 102ms/step - loss: 2.7899 - species_accuracy: 0.3187 - species_loss: 2.5951 - venom_accuracy: 0.8371 - venom_loss: 0.3897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:29:44.093923: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.8883 - species_accuracy: 0.3031 - species_loss: 2.6914 - venom_accuracy: 0.8316 - venom_loss: 0.3939\n",
      "Epoch 11: val_loss did not improve from 3.88761\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 143ms/step - loss: 2.9388 - species_accuracy: 0.2955 - species_loss: 2.7411 - venom_accuracy: 0.8291 - venom_loss: 0.3955 - val_loss: 3.9071 - val_species_accuracy: 0.2116 - val_species_loss: 3.7111 - val_venom_accuracy: 0.8332 - val_venom_loss: 0.3900 - learning_rate: 5.0000e-04\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 1/40\n",
      "\u001b[1m 563/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 97ms/step - loss: 2.6886 - species_accuracy: 0.2952 - species_loss: 2.7640 - venom_accuracy: 0.8285 - venom_loss: 0.3978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:33:42.311032: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 640/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 95ms/step - loss: 2.6903 - species_accuracy: 0.2946 - species_loss: 2.7658 - venom_accuracy: 0.8286 - venom_loss: 0.3981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.6875 - species_accuracy: 0.2945 - species_loss: 2.7634 - venom_accuracy: 0.8289 - venom_loss: 0.3973\n",
      "Epoch 1: val_loss improved from None to 3.40255, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 144ms/step - loss: 2.6797 - species_accuracy: 0.2967 - species_loss: 2.7581 - venom_accuracy: 0.8290 - venom_loss: 0.3945 - val_loss: 3.4025 - val_species_accuracy: 0.2116 - val_species_loss: 3.6677 - val_venom_accuracy: 0.8322 - val_venom_loss: 0.3910\n",
      "Epoch 2/40\n",
      "\u001b[1m 501/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 92ms/step - loss: 2.7010 - species_accuracy: 0.3048 - species_loss: 2.7680 - venom_accuracy: 0.8216 - venom_loss: 0.4055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:36:54.080688: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 618/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 91ms/step - loss: 2.6934 - species_accuracy: 0.3055 - species_loss: 2.7612 - venom_accuracy: 0.8225 - venom_loss: 0.4038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.6713 - species_accuracy: 0.3074 - species_loss: 2.7398 - venom_accuracy: 0.8252 - venom_loss: 0.3995\n",
      "Epoch 2: val_loss improved from 3.40255 to 3.39536, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 141ms/step - loss: 2.6486 - species_accuracy: 0.3082 - species_loss: 2.7188 - venom_accuracy: 0.8287 - venom_loss: 0.3946 - val_loss: 3.3954 - val_species_accuracy: 0.2119 - val_species_loss: 3.6595 - val_venom_accuracy: 0.8324 - val_venom_loss: 0.3902\n",
      "Epoch 3/40\n",
      "\u001b[1m 627/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 96ms/step - loss: 2.5789 - species_accuracy: 0.3139 - species_loss: 2.6529 - venom_accuracy: 0.8347 - venom_loss: 0.3805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:40:24.082912: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1011/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 96ms/step - loss: 2.5922 - species_accuracy: 0.3119 - species_loss: 2.6647 - venom_accuracy: 0.8334 - venom_loss: 0.3837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.5997 - species_accuracy: 0.3108 - species_loss: 2.6711 - venom_accuracy: 0.8323 - venom_loss: 0.3857\n",
      "Epoch 3: val_loss improved from 3.39536 to 3.39406, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 142ms/step - loss: 2.6235 - species_accuracy: 0.3083 - species_loss: 2.6920 - venom_accuracy: 0.8298 - venom_loss: 0.3914 - val_loss: 3.3941 - val_species_accuracy: 0.2124 - val_species_loss: 3.6575 - val_venom_accuracy: 0.8330 - val_venom_loss: 0.3890\n",
      "Epoch 4/40\n",
      "\u001b[1m 380/1385\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30\u001b[0m 90ms/step - loss: 2.6062 - species_accuracy: 0.3105 - species_loss: 2.6597 - venom_accuracy: 0.8243 - venom_loss: 0.3987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:43:14.879755: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 624/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 87ms/step - loss: 2.6077 - species_accuracy: 0.3127 - species_loss: 2.6660 - venom_accuracy: 0.8263 - venom_loss: 0.3957"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.6093 - species_accuracy: 0.3131 - species_loss: 2.6730 - venom_accuracy: 0.8287 - venom_loss: 0.3924\n",
      "Epoch 4: val_loss improved from 3.39406 to 3.39098, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 137ms/step - loss: 2.6111 - species_accuracy: 0.3130 - species_loss: 2.6773 - venom_accuracy: 0.8293 - venom_loss: 0.3912 - val_loss: 3.3910 - val_species_accuracy: 0.2137 - val_species_loss: 3.6551 - val_venom_accuracy: 0.8336 - val_venom_loss: 0.3890\n",
      "Epoch 5/40\n",
      "\u001b[1m  84/1385\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 87ms/step - loss: 2.6147 - species_accuracy: 0.3207 - species_loss: 2.6548 - venom_accuracy: 0.8124 - venom_loss: 0.4090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:45:57.673662: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 735/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 91ms/step - loss: 2.6188 - species_accuracy: 0.3173 - species_loss: 2.6758 - venom_accuracy: 0.8232 - venom_loss: 0.3985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.6139 - species_accuracy: 0.3166 - species_loss: 2.6753 - venom_accuracy: 0.8257 - venom_loss: 0.3947\n",
      "Epoch 5: val_loss improved from 3.39098 to 3.38934, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 139ms/step - loss: 2.6019 - species_accuracy: 0.3169 - species_loss: 2.6671 - venom_accuracy: 0.8300 - venom_loss: 0.3902 - val_loss: 3.3893 - val_species_accuracy: 0.2140 - val_species_loss: 3.6534 - val_venom_accuracy: 0.8336 - val_venom_loss: 0.3887\n",
      "Epoch 6/40\n",
      "\u001b[1m 705/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 98ms/step - loss: 2.5897 - species_accuracy: 0.3176 - species_loss: 2.6484 - venom_accuracy: 0.8283 - venom_loss: 0.3924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1294/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - loss: 2.5941 - species_accuracy: 0.3157 - species_loss: 2.6542 - venom_accuracy: 0.8287 - venom_loss: 0.3923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:51:09.169250: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2.5944 - species_accuracy: 0.3157 - species_loss: 2.6546 - venom_accuracy: 0.8287 - venom_loss: 0.3922\n",
      "Epoch 6: val_loss improved from 3.38934 to 3.38731, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 146ms/step - loss: 2.5959 - species_accuracy: 0.3144 - species_loss: 2.6587 - venom_accuracy: 0.8294 - venom_loss: 0.3904 - val_loss: 3.3873 - val_species_accuracy: 0.2148 - val_species_loss: 3.6515 - val_venom_accuracy: 0.8342 - val_venom_loss: 0.3886\n",
      "Epoch 7/40\n",
      "\u001b[1m 486/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 92ms/step - loss: 2.6135 - species_accuracy: 0.3153 - species_loss: 2.6767 - venom_accuracy: 0.8299 - venom_loss: 0.3935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1100/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26s\u001b[0m 94ms/step - loss: 2.6011 - species_accuracy: 0.3157 - species_loss: 2.6653 - venom_accuracy: 0.8310 - venom_loss: 0.3907"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:54:08.259890: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.5986 - species_accuracy: 0.3158 - species_loss: 2.6627 - venom_accuracy: 0.8311 - venom_loss: 0.3904\n",
      "Epoch 7: val_loss improved from 3.38731 to 3.38553, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 141ms/step - loss: 2.5893 - species_accuracy: 0.3161 - species_loss: 2.6522 - venom_accuracy: 0.8312 - venom_loss: 0.3896 - val_loss: 3.3855 - val_species_accuracy: 0.2153 - val_species_loss: 3.6497 - val_venom_accuracy: 0.8341 - val_venom_loss: 0.3881\n",
      "Epoch 8/40\n",
      "\u001b[1m 686/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 91ms/step - loss: 2.5637 - species_accuracy: 0.3180 - species_loss: 2.6241 - venom_accuracy: 0.8327 - venom_loss: 0.3871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1063/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - loss: 2.5671 - species_accuracy: 0.3184 - species_loss: 2.6267 - venom_accuracy: 0.8317 - venom_loss: 0.3881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:57:17.387037: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.5684 - species_accuracy: 0.3187 - species_loss: 2.6281 - venom_accuracy: 0.8314 - venom_loss: 0.3883\n",
      "Epoch 8: val_loss improved from 3.38553 to 3.38368, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 141ms/step - loss: 2.5759 - species_accuracy: 0.3192 - species_loss: 2.6359 - venom_accuracy: 0.8303 - venom_loss: 0.3893 - val_loss: 3.3837 - val_species_accuracy: 0.2149 - val_species_loss: 3.6473 - val_venom_accuracy: 0.8343 - val_venom_loss: 0.3878\n",
      "Epoch 9/40\n",
      "\u001b[1m 109/1385\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 87ms/step - loss: 2.5897 - species_accuracy: 0.3300 - species_loss: 2.6447 - venom_accuracy: 0.8251 - venom_loss: 0.3949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1316/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5858 - species_accuracy: 0.3217 - species_loss: 2.6415 - venom_accuracy: 0.8273 - venom_loss: 0.3939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:00:54.355984: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.5856 - species_accuracy: 0.3215 - species_loss: 2.6414 - venom_accuracy: 0.8274 - venom_loss: 0.3937\n",
      "Epoch 9: val_loss improved from 3.38368 to 3.38160, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 138ms/step - loss: 2.5796 - species_accuracy: 0.3176 - species_loss: 2.6400 - venom_accuracy: 0.8292 - venom_loss: 0.3898 - val_loss: 3.3816 - val_species_accuracy: 0.2153 - val_species_loss: 3.6463 - val_venom_accuracy: 0.8342 - val_venom_loss: 0.3880\n",
      "Epoch 10/40\n",
      "\u001b[1m 585/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 98ms/step - loss: 2.5797 - species_accuracy: 0.3224 - species_loss: 2.6384 - venom_accuracy: 0.8281 - venom_loss: 0.3908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1352/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 2.5766 - species_accuracy: 0.3208 - species_loss: 2.6341 - venom_accuracy: 0.8287 - venom_loss: 0.3911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:04:17.457492: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.5767 - species_accuracy: 0.3208 - species_loss: 2.6342 - venom_accuracy: 0.8287 - venom_loss: 0.3911\n",
      "Epoch 10: val_loss improved from 3.38160 to 3.38131, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 145ms/step - loss: 2.5773 - species_accuracy: 0.3192 - species_loss: 2.6363 - venom_accuracy: 0.8298 - venom_loss: 0.3900 - val_loss: 3.3813 - val_species_accuracy: 0.2164 - val_species_loss: 3.6461 - val_venom_accuracy: 0.8340 - val_venom_loss: 0.3875\n",
      "Epoch 11/40\n",
      "\u001b[1m 206/1385\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 85ms/step - loss: 2.5343 - species_accuracy: 0.3295 - species_loss: 2.5720 - venom_accuracy: 0.8260 - venom_loss: 0.3973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:05:46.394993: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1178/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m18s\u001b[0m 91ms/step - loss: 2.5523 - species_accuracy: 0.3239 - species_loss: 2.6079 - venom_accuracy: 0.8310 - venom_loss: 0.3884"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.5542 - species_accuracy: 0.3235 - species_loss: 2.6105 - venom_accuracy: 0.8312 - venom_loss: 0.3882\n",
      "Epoch 11: val_loss improved from 3.38131 to 3.37972, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 139ms/step - loss: 2.5684 - species_accuracy: 0.3214 - species_loss: 2.6278 - venom_accuracy: 0.8311 - venom_loss: 0.3887 - val_loss: 3.3797 - val_species_accuracy: 0.2160 - val_species_loss: 3.6436 - val_venom_accuracy: 0.8343 - val_venom_loss: 0.3868\n",
      "Epoch 12/40\n",
      "\u001b[1m 238/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 101ms/step - loss: 2.5578 - species_accuracy: 0.3297 - species_loss: 2.6050 - venom_accuracy: 0.8249 - venom_loss: 0.3948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1002/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 96ms/step - loss: 2.5648 - species_accuracy: 0.3241 - species_loss: 2.6147 - venom_accuracy: 0.8281 - venom_loss: 0.3942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:10:17.483710: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.5659 - species_accuracy: 0.3234 - species_loss: 2.6174 - venom_accuracy: 0.8286 - venom_loss: 0.3933\n",
      "Epoch 12: val_loss did not improve from 3.37972\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 144ms/step - loss: 2.5619 - species_accuracy: 0.3220 - species_loss: 2.6169 - venom_accuracy: 0.8301 - venom_loss: 0.3902 - val_loss: 3.3801 - val_species_accuracy: 0.2162 - val_species_loss: 3.6427 - val_venom_accuracy: 0.8346 - val_venom_loss: 0.3874\n",
      "Epoch 13/40\n",
      "\u001b[1m 743/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 90ms/step - loss: 2.5776 - species_accuracy: 0.3196 - species_loss: 2.6346 - venom_accuracy: 0.8272 - venom_loss: 0.3916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:13:08.009487: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 896/1385\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 89ms/step - loss: 2.5744 - species_accuracy: 0.3200 - species_loss: 2.6317 - venom_accuracy: 0.8277 - venom_loss: 0.3909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5692 - species_accuracy: 0.3203 - species_loss: 2.6273 - venom_accuracy: 0.8289 - venom_loss: 0.3895\n",
      "Epoch 13: val_loss improved from 3.37972 to 3.37734, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 135ms/step - loss: 2.5585 - species_accuracy: 0.3211 - species_loss: 2.6165 - venom_accuracy: 0.8308 - venom_loss: 0.3880 - val_loss: 3.3773 - val_species_accuracy: 0.2167 - val_species_loss: 3.6403 - val_venom_accuracy: 0.8340 - val_venom_loss: 0.3873\n",
      "Epoch 14/40\n",
      "\u001b[1m 120/1385\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 80ms/step - loss: 2.6174 - species_accuracy: 0.3090 - species_loss: 2.6870 - venom_accuracy: 0.8392 - venom_loss: 0.3899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 402/1385\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 90ms/step - loss: 2.5644 - species_accuracy: 0.3196 - species_loss: 2.6153 - venom_accuracy: 0.8335 - venom_loss: 0.3934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:15:44.787650: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.5583 - species_accuracy: 0.3238 - species_loss: 2.6100 - venom_accuracy: 0.8312 - venom_loss: 0.3919\n",
      "Epoch 14: val_loss improved from 3.37734 to 3.37541, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 136ms/step - loss: 2.5573 - species_accuracy: 0.3245 - species_loss: 2.6117 - venom_accuracy: 0.8302 - venom_loss: 0.3901 - val_loss: 3.3754 - val_species_accuracy: 0.2173 - val_species_loss: 3.6404 - val_venom_accuracy: 0.8345 - val_venom_loss: 0.3868\n",
      "Epoch 15/40\n",
      "\u001b[1m  84/1385\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 128ms/step - loss: 2.5727 - species_accuracy: 0.2934 - species_loss: 2.6382 - venom_accuracy: 0.8264 - venom_loss: 0.3852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 935/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 97ms/step - loss: 2.5710 - species_accuracy: 0.3192 - species_loss: 2.6293 - venom_accuracy: 0.8280 - venom_loss: 0.3896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:19:48.011565: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.5671 - species_accuracy: 0.3206 - species_loss: 2.6257 - venom_accuracy: 0.8287 - venom_loss: 0.3888\n",
      "Epoch 15: val_loss did not improve from 3.37541\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 144ms/step - loss: 2.5574 - species_accuracy: 0.3220 - species_loss: 2.6158 - venom_accuracy: 0.8301 - venom_loss: 0.3871 - val_loss: 3.3756 - val_species_accuracy: 0.2169 - val_species_loss: 3.6413 - val_venom_accuracy: 0.8342 - val_venom_loss: 0.3870\n",
      "Epoch 16/40\n",
      "\u001b[1m 761/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 95ms/step - loss: 2.4944 - species_accuracy: 0.3286 - species_loss: 2.5616 - venom_accuracy: 0.8409 - venom_loss: 0.3709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1195/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m17s\u001b[0m 94ms/step - loss: 2.5083 - species_accuracy: 0.3270 - species_loss: 2.5712 - venom_accuracy: 0.8383 - venom_loss: 0.3762"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:23:29.958600: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.5128 - species_accuracy: 0.3265 - species_loss: 2.5743 - venom_accuracy: 0.8372 - venom_loss: 0.3778\n",
      "Epoch 16: val_loss improved from 3.37541 to 3.37474, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 139ms/step - loss: 2.5440 - species_accuracy: 0.3229 - species_loss: 2.5960 - venom_accuracy: 0.8301 - venom_loss: 0.3898 - val_loss: 3.3747 - val_species_accuracy: 0.2178 - val_species_loss: 3.6404 - val_venom_accuracy: 0.8342 - val_venom_loss: 0.3861\n",
      "Epoch 17/40\n",
      "\u001b[1m 768/1385\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 94ms/step - loss: 2.5453 - species_accuracy: 0.3256 - species_loss: 2.5885 - venom_accuracy: 0.8227 - venom_loss: 0.3954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1028/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 95ms/step - loss: 2.5459 - species_accuracy: 0.3252 - species_loss: 2.5915 - venom_accuracy: 0.8243 - venom_loss: 0.3940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:26:27.970594: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.5457 - species_accuracy: 0.3253 - species_loss: 2.5931 - venom_accuracy: 0.8257 - venom_loss: 0.3927\n",
      "Epoch 17: val_loss improved from 3.37474 to 3.37464, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 158ms/step - loss: 2.5428 - species_accuracy: 0.3259 - species_loss: 2.5973 - venom_accuracy: 0.8298 - venom_loss: 0.3874 - val_loss: 3.3746 - val_species_accuracy: 0.2171 - val_species_loss: 3.6383 - val_venom_accuracy: 0.8342 - val_venom_loss: 0.3868\n",
      "Epoch 18/40\n",
      "\u001b[1m 327/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 94ms/step - loss: 2.5379 - species_accuracy: 0.3350 - species_loss: 2.5827 - venom_accuracy: 0.8317 - venom_loss: 0.3931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:29:00.054251: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1046/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m31s\u001b[0m 94ms/step - loss: 2.5336 - species_accuracy: 0.3316 - species_loss: 2.5848 - venom_accuracy: 0.8325 - venom_loss: 0.3881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 2.5350 - species_accuracy: 0.3305 - species_loss: 2.5866 - venom_accuracy: 0.8320 - venom_loss: 0.3880\n",
      "Epoch 18: val_loss improved from 3.37464 to 3.37411, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 143ms/step - loss: 2.5380 - species_accuracy: 0.3271 - species_loss: 2.5912 - venom_accuracy: 0.8306 - venom_loss: 0.3876 - val_loss: 3.3741 - val_species_accuracy: 0.2176 - val_species_loss: 3.6386 - val_venom_accuracy: 0.8343 - val_venom_loss: 0.3866\n",
      "Epoch 19/40\n",
      "\u001b[1m 492/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 92ms/step - loss: 2.5592 - species_accuracy: 0.3210 - species_loss: 2.6230 - venom_accuracy: 0.8298 - venom_loss: 0.3840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:32:32.702905: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 592/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 97ms/step - loss: 2.5591 - species_accuracy: 0.3221 - species_loss: 2.6224 - venom_accuracy: 0.8298 - venom_loss: 0.3843"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2.5498 - species_accuracy: 0.3258 - species_loss: 2.6078 - venom_accuracy: 0.8297 - venom_loss: 0.3863\n",
      "Epoch 19: val_loss improved from 3.37411 to 3.37267, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 144ms/step - loss: 2.5322 - species_accuracy: 0.3274 - species_loss: 2.5862 - venom_accuracy: 0.8313 - venom_loss: 0.3858 - val_loss: 3.3727 - val_species_accuracy: 0.2175 - val_species_loss: 3.6348 - val_venom_accuracy: 0.8345 - val_venom_loss: 0.3877\n",
      "Epoch 20/40\n",
      "\u001b[1m 613/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 109ms/step - loss: 2.5203 - species_accuracy: 0.3269 - species_loss: 2.5622 - venom_accuracy: 0.8261 - venom_loss: 0.3921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:36:13.363200: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 763/1385\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 106ms/step - loss: 2.5218 - species_accuracy: 0.3268 - species_loss: 2.5647 - venom_accuracy: 0.8263 - venom_loss: 0.3917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 2.5264 - species_accuracy: 0.3268 - species_loss: 2.5711 - venom_accuracy: 0.8272 - venom_loss: 0.3913\n",
      "Epoch 20: val_loss improved from 3.37267 to 3.37142, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 154ms/step - loss: 2.5244 - species_accuracy: 0.3279 - species_loss: 2.5724 - venom_accuracy: 0.8303 - venom_loss: 0.3889 - val_loss: 3.3714 - val_species_accuracy: 0.2174 - val_species_loss: 3.6333 - val_venom_accuracy: 0.8345 - val_venom_loss: 0.3866\n",
      "Epoch 21/40\n",
      "\u001b[1m 165/1385\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 105ms/step - loss: 2.5661 - species_accuracy: 0.3246 - species_loss: 2.6473 - venom_accuracy: 0.8394 - venom_loss: 0.3736"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:38:57.770006: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 977/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 100ms/step - loss: 2.5349 - species_accuracy: 0.3265 - species_loss: 2.5954 - venom_accuracy: 0.8338 - venom_loss: 0.3822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.5329 - species_accuracy: 0.3267 - species_loss: 2.5907 - venom_accuracy: 0.8326 - venom_loss: 0.3837\n",
      "Epoch 21: val_loss improved from 3.37142 to 3.36969, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 152ms/step - loss: 2.5295 - species_accuracy: 0.3264 - species_loss: 2.5800 - venom_accuracy: 0.8293 - venom_loss: 0.3880 - val_loss: 3.3697 - val_species_accuracy: 0.2182 - val_species_loss: 3.6319 - val_venom_accuracy: 0.8342 - val_venom_loss: 0.3859\n",
      "Epoch 22/40\n",
      "\u001b[1m  65/1385\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 93ms/step - loss: 2.4841 - species_accuracy: 0.3325 - species_loss: 2.5141 - venom_accuracy: 0.8318 - venom_loss: 0.3940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:42:17.116400: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 970/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 97ms/step - loss: 2.5132 - species_accuracy: 0.3318 - species_loss: 2.5520 - venom_accuracy: 0.8289 - venom_loss: 0.3930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2.5172 - species_accuracy: 0.3309 - species_loss: 2.5587 - venom_accuracy: 0.8293 - venom_loss: 0.3918\n",
      "Epoch 22: val_loss improved from 3.36969 to 3.36815, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 146ms/step - loss: 2.5255 - species_accuracy: 0.3282 - species_loss: 2.5763 - venom_accuracy: 0.8312 - venom_loss: 0.3870 - val_loss: 3.3682 - val_species_accuracy: 0.2186 - val_species_loss: 3.6309 - val_venom_accuracy: 0.8344 - val_venom_loss: 0.3860\n",
      "Epoch 23/40\n",
      "\u001b[1m1104/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - loss: 2.5248 - species_accuracy: 0.3300 - species_loss: 2.5679 - venom_accuracy: 0.8288 - venom_loss: 0.3920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1279/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - loss: 2.5240 - species_accuracy: 0.3294 - species_loss: 2.5679 - venom_accuracy: 0.8291 - venom_loss: 0.3914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:47:39.422083: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.5235 - species_accuracy: 0.3293 - species_loss: 2.5678 - venom_accuracy: 0.8293 - venom_loss: 0.3911\n",
      "Epoch 23: val_loss improved from 3.36815 to 3.36767, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 152ms/step - loss: 2.5169 - species_accuracy: 0.3275 - species_loss: 2.5663 - venom_accuracy: 0.8315 - venom_loss: 0.3865 - val_loss: 3.3677 - val_species_accuracy: 0.2184 - val_species_loss: 3.6315 - val_venom_accuracy: 0.8343 - val_venom_loss: 0.3862\n",
      "Epoch 24/40\n",
      "\u001b[1m 769/1385\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 110ms/step - loss: 2.5268 - species_accuracy: 0.3287 - species_loss: 2.5817 - venom_accuracy: 0.8338 - venom_loss: 0.3845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 910/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 118ms/step - loss: 2.5249 - species_accuracy: 0.3286 - species_loss: 2.5789 - venom_accuracy: 0.8334 - venom_loss: 0.3848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:50:51.946845: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 2.5220 - species_accuracy: 0.3284 - species_loss: 2.5742 - venom_accuracy: 0.8327 - venom_loss: 0.3855\n",
      "Epoch 24: val_loss improved from 3.36767 to 3.36722, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 165ms/step - loss: 2.5167 - species_accuracy: 0.3277 - species_loss: 2.5689 - venom_accuracy: 0.8325 - venom_loss: 0.3847 - val_loss: 3.3672 - val_species_accuracy: 0.2190 - val_species_loss: 3.6305 - val_venom_accuracy: 0.8345 - val_venom_loss: 0.3866\n",
      "Epoch 25/40\n",
      "\u001b[1m 285/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 86ms/step - loss: 2.5233 - species_accuracy: 0.3264 - species_loss: 2.5657 - venom_accuracy: 0.8325 - venom_loss: 0.3923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:53:17.247141: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1127/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - loss: 2.5084 - species_accuracy: 0.3287 - species_loss: 2.5568 - venom_accuracy: 0.8345 - venom_loss: 0.3858"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 2.5079 - species_accuracy: 0.3289 - species_loss: 2.5564 - venom_accuracy: 0.8343 - venom_loss: 0.3856\n",
      "Epoch 25: val_loss improved from 3.36722 to 3.36526, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 139ms/step - loss: 2.5092 - species_accuracy: 0.3298 - species_loss: 2.5582 - venom_accuracy: 0.8329 - venom_loss: 0.3854 - val_loss: 3.3653 - val_species_accuracy: 0.2187 - val_species_loss: 3.6278 - val_venom_accuracy: 0.8343 - val_venom_loss: 0.3855\n",
      "Epoch 26/40\n",
      "\u001b[1m 408/1385\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 95ms/step - loss: 2.5127 - species_accuracy: 0.3313 - species_loss: 2.5594 - venom_accuracy: 0.8301 - venom_loss: 0.3876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:56:43.909482: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1348/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 2.5096 - species_accuracy: 0.3306 - species_loss: 2.5562 - venom_accuracy: 0.8304 - venom_loss: 0.3872"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.5097 - species_accuracy: 0.3306 - species_loss: 2.5563 - venom_accuracy: 0.8304 - venom_loss: 0.3872\n",
      "Epoch 26: val_loss improved from 3.36526 to 3.36436, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 141ms/step - loss: 2.5137 - species_accuracy: 0.3299 - species_loss: 2.5626 - venom_accuracy: 0.8306 - venom_loss: 0.3863 - val_loss: 3.3644 - val_species_accuracy: 0.2196 - val_species_loss: 3.6260 - val_venom_accuracy: 0.8344 - val_venom_loss: 0.3857\n",
      "Epoch 27/40\n",
      "\u001b[1m 339/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 97ms/step - loss: 2.5286 - species_accuracy: 0.3309 - species_loss: 2.5826 - venom_accuracy: 0.8298 - venom_loss: 0.3854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:59:52.821618: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 714/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 95ms/step - loss: 2.5130 - species_accuracy: 0.3338 - species_loss: 2.5670 - venom_accuracy: 0.8333 - venom_loss: 0.3829"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.5093 - species_accuracy: 0.3333 - species_loss: 2.5614 - venom_accuracy: 0.8333 - venom_loss: 0.3835\n",
      "Epoch 27: val_loss improved from 3.36436 to 3.36275, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 144ms/step - loss: 2.5076 - species_accuracy: 0.3308 - species_loss: 2.5586 - venom_accuracy: 0.8330 - venom_loss: 0.3839 - val_loss: 3.3627 - val_species_accuracy: 0.2197 - val_species_loss: 3.6243 - val_venom_accuracy: 0.8340 - val_venom_loss: 0.3857\n",
      "Epoch 28/40\n",
      "\u001b[1m 137/1385\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 87ms/step - loss: 2.5037 - species_accuracy: 0.3343 - species_loss: 2.5257 - venom_accuracy: 0.8233 - venom_loss: 0.4026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1230/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14s\u001b[0m 95ms/step - loss: 2.5256 - species_accuracy: 0.3319 - species_loss: 2.5667 - venom_accuracy: 0.8261 - venom_loss: 0.3935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:04:36.418944: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 2.5249 - species_accuracy: 0.3318 - species_loss: 2.5669 - venom_accuracy: 0.8266 - venom_loss: 0.3928\n",
      "Epoch 28: val_loss did not improve from 3.36275\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 142ms/step - loss: 2.5180 - species_accuracy: 0.3305 - species_loss: 2.5673 - venom_accuracy: 0.8303 - venom_loss: 0.3870 - val_loss: 3.3631 - val_species_accuracy: 0.2194 - val_species_loss: 3.6254 - val_venom_accuracy: 0.8345 - val_venom_loss: 0.3866\n",
      "Epoch 29/40\n",
      "\u001b[1m 571/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 98ms/step - loss: 2.5071 - species_accuracy: 0.3273 - species_loss: 2.5627 - venom_accuracy: 0.8355 - venom_loss: 0.3808"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 888/1385\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 97ms/step - loss: 2.5030 - species_accuracy: 0.3291 - species_loss: 2.5556 - venom_accuracy: 0.8345 - venom_loss: 0.3821"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:07:23.327441: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.4998 - species_accuracy: 0.3310 - species_loss: 2.5506 - venom_accuracy: 0.8339 - venom_loss: 0.3828\n",
      "Epoch 29: val_loss improved from 3.36275 to 3.36099, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 141ms/step - loss: 2.5002 - species_accuracy: 0.3336 - species_loss: 2.5460 - venom_accuracy: 0.8320 - venom_loss: 0.3862 - val_loss: 3.3610 - val_species_accuracy: 0.2202 - val_species_loss: 3.6239 - val_venom_accuracy: 0.8342 - val_venom_loss: 0.3851\n",
      "Epoch 30/40\n",
      "\u001b[1m1230/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14s\u001b[0m 91ms/step - loss: 2.4931 - species_accuracy: 0.3391 - species_loss: 2.5341 - venom_accuracy: 0.8314 - venom_loss: 0.3882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:11:04.301075: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1296/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - loss: 2.4933 - species_accuracy: 0.3390 - species_loss: 2.5346 - venom_accuracy: 0.8314 - venom_loss: 0.3880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.4938 - species_accuracy: 0.3387 - species_loss: 2.5354 - venom_accuracy: 0.8314 - venom_loss: 0.3879\n",
      "Epoch 30: val_loss did not improve from 3.36099\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 139ms/step - loss: 2.5000 - species_accuracy: 0.3354 - species_loss: 2.5466 - venom_accuracy: 0.8313 - venom_loss: 0.3858 - val_loss: 3.3620 - val_species_accuracy: 0.2204 - val_species_loss: 3.6243 - val_venom_accuracy: 0.8343 - val_venom_loss: 0.3852\n",
      "Epoch 31/40\n",
      "\u001b[1m 400/1385\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 94ms/step - loss: 2.5206 - species_accuracy: 0.3395 - species_loss: 2.5591 - venom_accuracy: 0.8252 - venom_loss: 0.3944"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1021/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 95ms/step - loss: 2.5103 - species_accuracy: 0.3359 - species_loss: 2.5521 - venom_accuracy: 0.8273 - venom_loss: 0.3905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:14:01.964594: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.5080 - species_accuracy: 0.3349 - species_loss: 2.5507 - venom_accuracy: 0.8281 - venom_loss: 0.3896\n",
      "Epoch 31: val_loss improved from 3.36099 to 3.36081, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 143ms/step - loss: 2.4974 - species_accuracy: 0.3321 - species_loss: 2.5422 - venom_accuracy: 0.8314 - venom_loss: 0.3864 - val_loss: 3.3608 - val_species_accuracy: 0.2204 - val_species_loss: 3.6216 - val_venom_accuracy: 0.8345 - val_venom_loss: 0.3856\n",
      "Epoch 32/40\n",
      "\u001b[1m 254/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 100ms/step - loss: 2.4894 - species_accuracy: 0.3291 - species_loss: 2.5387 - venom_accuracy: 0.8385 - venom_loss: 0.3820"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1379/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.4917 - species_accuracy: 0.3331 - species_loss: 2.5402 - venom_accuracy: 0.8347 - venom_loss: 0.3829"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:17:55.683978: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.4917 - species_accuracy: 0.3331 - species_loss: 2.5402 - venom_accuracy: 0.8347 - venom_loss: 0.3829\n",
      "Epoch 32: val_loss improved from 3.36081 to 3.36049, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 145ms/step - loss: 2.4984 - species_accuracy: 0.3335 - species_loss: 2.5455 - venom_accuracy: 0.8325 - venom_loss: 0.3852 - val_loss: 3.3605 - val_species_accuracy: 0.2205 - val_species_loss: 3.6241 - val_venom_accuracy: 0.8344 - val_venom_loss: 0.3849\n",
      "Epoch 33/40\n",
      "\u001b[1m 497/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 93ms/step - loss: 2.4926 - species_accuracy: 0.3365 - species_loss: 2.5367 - venom_accuracy: 0.8315 - venom_loss: 0.3860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1231/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14s\u001b[0m 94ms/step - loss: 2.4933 - species_accuracy: 0.3361 - species_loss: 2.5364 - venom_accuracy: 0.8314 - venom_loss: 0.3869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:20:59.323329: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.4933 - species_accuracy: 0.3360 - species_loss: 2.5367 - venom_accuracy: 0.8316 - venom_loss: 0.3866\n",
      "Epoch 33: val_loss did not improve from 3.36049\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 142ms/step - loss: 2.4907 - species_accuracy: 0.3350 - species_loss: 2.5373 - venom_accuracy: 0.8330 - venom_loss: 0.3842 - val_loss: 3.3606 - val_species_accuracy: 0.2205 - val_species_loss: 3.6226 - val_venom_accuracy: 0.8345 - val_venom_loss: 0.3859\n",
      "Epoch 34/40\n",
      "\u001b[1m 365/1385\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 96ms/step - loss: 2.4753 - species_accuracy: 0.3334 - species_loss: 2.5237 - venom_accuracy: 0.8335 - venom_loss: 0.3803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 453/1385\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 93ms/step - loss: 2.4748 - species_accuracy: 0.3339 - species_loss: 2.5227 - venom_accuracy: 0.8337 - venom_loss: 0.3805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:23:02.950749: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 2.4802 - species_accuracy: 0.3348 - species_loss: 2.5268 - venom_accuracy: 0.8332 - venom_loss: 0.3823\n",
      "Epoch 34: val_loss improved from 3.36049 to 3.35920, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 140ms/step - loss: 2.4916 - species_accuracy: 0.3333 - species_loss: 2.5386 - venom_accuracy: 0.8326 - venom_loss: 0.3840 - val_loss: 3.3592 - val_species_accuracy: 0.2201 - val_species_loss: 3.6207 - val_venom_accuracy: 0.8344 - val_venom_loss: 0.3852\n",
      "Epoch 35/40\n",
      "\u001b[1m 274/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 98ms/step - loss: 2.4514 - species_accuracy: 0.3368 - species_loss: 2.4914 - venom_accuracy: 0.8336 - venom_loss: 0.3818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 346/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 95ms/step - loss: 2.4534 - species_accuracy: 0.3363 - species_loss: 2.4951 - venom_accuracy: 0.8338 - venom_loss: 0.3811"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:26:07.650431: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.4656 - species_accuracy: 0.3353 - species_loss: 2.5120 - venom_accuracy: 0.8348 - venom_loss: 0.3800\n",
      "Epoch 35: val_loss improved from 3.35920 to 3.35841, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 144ms/step - loss: 2.4803 - species_accuracy: 0.3353 - species_loss: 2.5273 - venom_accuracy: 0.8330 - venom_loss: 0.3822 - val_loss: 3.3584 - val_species_accuracy: 0.2206 - val_species_loss: 3.6218 - val_venom_accuracy: 0.8345 - val_venom_loss: 0.3847\n",
      "Epoch 36/40\n",
      "\u001b[1m 339/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 96ms/step - loss: 2.4383 - species_accuracy: 0.3481 - species_loss: 2.4763 - venom_accuracy: 0.8329 - venom_loss: 0.3811"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:29:27.066488: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 497/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 92ms/step - loss: 2.4460 - species_accuracy: 0.3472 - species_loss: 2.4842 - venom_accuracy: 0.8321 - venom_loss: 0.3822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.4671 - species_accuracy: 0.3416 - species_loss: 2.5072 - venom_accuracy: 0.8315 - venom_loss: 0.3845\n",
      "Epoch 36: val_loss did not improve from 3.35841\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 137ms/step - loss: 2.4787 - species_accuracy: 0.3374 - species_loss: 2.5230 - venom_accuracy: 0.8327 - venom_loss: 0.3838 - val_loss: 3.3589 - val_species_accuracy: 0.2206 - val_species_loss: 3.6222 - val_venom_accuracy: 0.8349 - val_venom_loss: 0.3846\n",
      "Epoch 37/40\n",
      "\u001b[1m 511/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 99ms/step - loss: 2.5064 - species_accuracy: 0.3342 - species_loss: 2.5450 - venom_accuracy: 0.8273 - venom_loss: 0.3920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 525/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 98ms/step - loss: 2.5066 - species_accuracy: 0.3341 - species_loss: 2.5455 - venom_accuracy: 0.8274 - venom_loss: 0.3918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:32:56.516077: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.4967 - species_accuracy: 0.3349 - species_loss: 2.5387 - venom_accuracy: 0.8298 - venom_loss: 0.3881\n",
      "Epoch 37: val_loss improved from 3.35841 to 3.35745, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 141ms/step - loss: 2.4818 - species_accuracy: 0.3366 - species_loss: 2.5241 - venom_accuracy: 0.8315 - venom_loss: 0.3855 - val_loss: 3.3574 - val_species_accuracy: 0.2212 - val_species_loss: 3.6201 - val_venom_accuracy: 0.8345 - val_venom_loss: 0.3853\n",
      "Epoch 38/40\n",
      "\u001b[1m  79/1385\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 85ms/step - loss: 2.4393 - species_accuracy: 0.3520 - species_loss: 2.5153 - venom_accuracy: 0.8556 - venom_loss: 0.3559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 225/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 85ms/step - loss: 2.4239 - species_accuracy: 0.3493 - species_loss: 2.4818 - venom_accuracy: 0.8451 - venom_loss: 0.3654"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:35:39.700190: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.4613 - species_accuracy: 0.3422 - species_loss: 2.5054 - venom_accuracy: 0.8342 - venom_loss: 0.3808\n",
      "Epoch 38: val_loss improved from 3.35745 to 3.35626, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 142ms/step - loss: 2.4835 - species_accuracy: 0.3391 - species_loss: 2.5264 - venom_accuracy: 0.8317 - venom_loss: 0.3852 - val_loss: 3.3563 - val_species_accuracy: 0.2211 - val_species_loss: 3.6171 - val_venom_accuracy: 0.8348 - val_venom_loss: 0.3850\n",
      "Epoch 39/40\n",
      "\u001b[1m 357/1385\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 96ms/step - loss: 2.4924 - species_accuracy: 0.3359 - species_loss: 2.5335 - venom_accuracy: 0.8253 - venom_loss: 0.3880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1204/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - loss: 2.4805 - species_accuracy: 0.3366 - species_loss: 2.5217 - venom_accuracy: 0.8285 - venom_loss: 0.3860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:40:27.193292: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.4803 - species_accuracy: 0.3368 - species_loss: 2.5216 - venom_accuracy: 0.8288 - venom_loss: 0.3858\n",
      "Epoch 39: val_loss did not improve from 3.35626\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 141ms/step - loss: 2.4774 - species_accuracy: 0.3388 - species_loss: 2.5202 - venom_accuracy: 0.8313 - venom_loss: 0.3848 - val_loss: 3.3572 - val_species_accuracy: 0.2214 - val_species_loss: 3.6192 - val_venom_accuracy: 0.8346 - val_venom_loss: 0.3850\n",
      "Epoch 40/40\n",
      "\u001b[1m 666/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 88ms/step - loss: 2.4958 - species_accuracy: 0.3423 - species_loss: 2.5379 - venom_accuracy: 0.8309 - venom_loss: 0.3879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:42:51.416857: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1148/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21s\u001b[0m 92ms/step - loss: 2.4890 - species_accuracy: 0.3409 - species_loss: 2.5319 - venom_accuracy: 0.8310 - venom_loss: 0.3863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 2.4865 - species_accuracy: 0.3404 - species_loss: 2.5295 - venom_accuracy: 0.8311 - venom_loss: 0.3858\n",
      "Epoch 40: val_loss improved from 3.35626 to 3.35536, saving model to best_model_fold1_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 139ms/step - loss: 2.4748 - species_accuracy: 0.3387 - species_loss: 2.5173 - venom_accuracy: 0.8310 - venom_loss: 0.3842 - val_loss: 3.3554 - val_species_accuracy: 0.2212 - val_species_loss: 3.6179 - val_venom_accuracy: 0.8346 - val_venom_loss: 0.3842\n",
      "Restoring model weights from the end of the best epoch: 40.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:45:52.062118: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Metrics ===\n",
      "1) Species accuracy: 0.2212\n",
      "2) Macro-averaged F1 (species): 0.2120\n",
      "3) Venom decision accuracy: 0.8346\n",
      "4) Venom-weighted species accuracy: 0.5027\n",
      "\n",
      "===== FOLD 2/3 =====\n",
      "Epoch 1/60\n",
      "\u001b[1m 311/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 95ms/step - loss: 5.8850 - species_accuracy: 0.0117 - species_loss: 5.6446 - venom_accuracy: 0.7996 - venom_loss: 0.4809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 5.4660 - species_accuracy: 0.0358 - species_loss: 5.2368 - venom_accuracy: 0.8041 - venom_loss: 0.4584"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:48:18.277846: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from None to 4.36930, saving model to best_model_fold2.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 136ms/step - loss: 5.0913 - species_accuracy: 0.0581 - species_loss: 4.8685 - venom_accuracy: 0.8067 - venom_loss: 0.4467 - val_loss: 4.3693 - val_species_accuracy: 0.1261 - val_species_loss: 4.1620 - val_venom_accuracy: 0.8240 - val_venom_loss: 0.4152 - learning_rate: 5.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m 269/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43\u001b[0m 93ms/step - loss: 4.4083 - species_accuracy: 0.1091 - species_loss: 4.1896 - venom_accuracy: 0.8096 - venom_loss: 0.4374"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4.3596 - species_accuracy: 0.1176 - species_loss: 4.1447 - venom_accuracy: 0.8127 - venom_loss: 0.4298"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:51:28.708007: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 4.36930 to 4.10716, saving model to best_model_fold2.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 135ms/step - loss: 4.3052 - species_accuracy: 0.1234 - species_loss: 4.0917 - venom_accuracy: 0.8144 - venom_loss: 0.4261 - val_loss: 4.1072 - val_species_accuracy: 0.1581 - val_species_loss: 3.9027 - val_venom_accuracy: 0.8271 - val_venom_loss: 0.4058 - learning_rate: 5.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m 587/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 95ms/step - loss: 3.9920 - species_accuracy: 0.1587 - species_loss: 3.7829 - venom_accuracy: 0.8177 - venom_loss: 0.4183"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 3.9998 - species_accuracy: 0.1583 - species_loss: 3.7910 - venom_accuracy: 0.8183 - venom_loss: 0.4178"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:55:20.344063: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss improved from 4.10716 to 4.02935, saving model to best_model_fold2.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 3.9946 - species_accuracy: 0.1590 - species_loss: 3.7861 - venom_accuracy: 0.8194 - venom_loss: 0.4169 - val_loss: 4.0294 - val_species_accuracy: 0.1725 - val_species_loss: 3.8321 - val_venom_accuracy: 0.8308 - val_venom_loss: 0.3990 - learning_rate: 5.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m  86/1385\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 78ms/step - loss: 3.6167 - species_accuracy: 0.1875 - species_loss: 3.4204 - venom_accuracy: 0.8323 - venom_loss: 0.3927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3.7473 - species_accuracy: 0.1869 - species_loss: 3.5427 - venom_accuracy: 0.8226 - venom_loss: 0.4093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 02:58:14.183367: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_loss improved from 4.02935 to 3.95036, saving model to best_model_fold2.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 3.7699 - species_accuracy: 0.1864 - species_loss: 3.5649 - venom_accuracy: 0.8227 - venom_loss: 0.4105 - val_loss: 3.9504 - val_species_accuracy: 0.1822 - val_species_loss: 3.7504 - val_venom_accuracy: 0.8290 - val_venom_loss: 0.3972 - learning_rate: 5.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m 883/1385\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 87ms/step - loss: 3.5290 - species_accuracy: 0.2135 - species_loss: 3.3263 - venom_accuracy: 0.8245 - venom_loss: 0.4054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3.5504 - species_accuracy: 0.2110 - species_loss: 3.3475 - venom_accuracy: 0.8244 - venom_loss: 0.4059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:00:35.612847: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: val_loss improved from 3.95036 to 3.93254, saving model to best_model_fold2.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 134ms/step - loss: 3.6016 - species_accuracy: 0.2057 - species_loss: 3.3985 - venom_accuracy: 0.8239 - venom_loss: 0.4067 - val_loss: 3.9325 - val_species_accuracy: 0.1901 - val_species_loss: 3.7328 - val_venom_accuracy: 0.8298 - val_venom_loss: 0.3976 - learning_rate: 5.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m 867/1385\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 87ms/step - loss: 3.4227 - species_accuracy: 0.2318 - species_loss: 3.2201 - venom_accuracy: 0.8242 - venom_loss: 0.4052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 3.4283 - species_accuracy: 0.2299 - species_loss: 3.2261 - venom_accuracy: 0.8243 - venom_loss: 0.4045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:04:21.087005: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_loss did not improve from 3.93254\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 3.4451 - species_accuracy: 0.2254 - species_loss: 3.2428 - venom_accuracy: 0.8248 - venom_loss: 0.4046 - val_loss: 3.9367 - val_species_accuracy: 0.1891 - val_species_loss: 3.7354 - val_venom_accuracy: 0.8288 - val_venom_loss: 0.4033 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m 669/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 84ms/step - loss: 3.2518 - species_accuracy: 0.2524 - species_loss: 3.0507 - venom_accuracy: 0.8251 - venom_loss: 0.4022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3.2776 - species_accuracy: 0.2489 - species_loss: 3.0763 - venom_accuracy: 0.8252 - venom_loss: 0.4025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:06:49.552938: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: val_loss improved from 3.93254 to 3.89886, saving model to best_model_fold2.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 3.3143 - species_accuracy: 0.2431 - species_loss: 3.1138 - venom_accuracy: 0.8259 - venom_loss: 0.4011 - val_loss: 3.8989 - val_species_accuracy: 0.2010 - val_species_loss: 3.6994 - val_venom_accuracy: 0.8299 - val_venom_loss: 0.4010 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m 932/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - loss: 3.1661 - species_accuracy: 0.2629 - species_loss: 2.9692 - venom_accuracy: 0.8299 - venom_loss: 0.3938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3.1752 - species_accuracy: 0.2606 - species_loss: 2.9774 - venom_accuracy: 0.8290 - venom_loss: 0.3957"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:10:41.134582: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: val_loss improved from 3.89886 to 3.87461, saving model to best_model_fold2.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 3.1980 - species_accuracy: 0.2559 - species_loss: 2.9975 - venom_accuracy: 0.8263 - venom_loss: 0.4005 - val_loss: 3.8746 - val_species_accuracy: 0.2057 - val_species_loss: 3.6773 - val_venom_accuracy: 0.8307 - val_venom_loss: 0.3951 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m 784/1385\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 83ms/step - loss: 3.0239 - species_accuracy: 0.2832 - species_loss: 2.8225 - venom_accuracy: 0.8219 - venom_loss: 0.4028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3.0583 - species_accuracy: 0.2779 - species_loss: 2.8576 - venom_accuracy: 0.8234 - venom_loss: 0.4013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:13:54.288118: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: val_loss did not improve from 3.87461\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 133ms/step - loss: 3.1173 - species_accuracy: 0.2676 - species_loss: 2.9176 - venom_accuracy: 0.8259 - venom_loss: 0.3989 - val_loss: 3.9078 - val_species_accuracy: 0.2041 - val_species_loss: 3.7104 - val_venom_accuracy: 0.8309 - val_venom_loss: 0.3968 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m 486/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 86ms/step - loss: 2.9399 - species_accuracy: 0.2929 - species_loss: 2.7447 - venom_accuracy: 0.8276 - venom_loss: 0.3905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2.9760 - species_accuracy: 0.2892 - species_loss: 2.7790 - venom_accuracy: 0.8266 - venom_loss: 0.3940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:16:02.189418: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: val_loss did not improve from 3.87461\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 3.0192 - species_accuracy: 0.2831 - species_loss: 2.8204 - venom_accuracy: 0.8264 - venom_loss: 0.3977 - val_loss: 3.9047 - val_species_accuracy: 0.2095 - val_species_loss: 3.7030 - val_venom_accuracy: 0.8297 - val_venom_loss: 0.4060 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m1047/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 2.8525 - species_accuracy: 0.3089 - species_loss: 2.6530 - venom_accuracy: 0.8248 - venom_loss: 0.3990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2.8654 - species_accuracy: 0.3062 - species_loss: 2.6664 - venom_accuracy: 0.8256 - venom_loss: 0.3980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:19:55.436960: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: val_loss did not improve from 3.87461\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 129ms/step - loss: 2.9118 - species_accuracy: 0.2959 - species_loss: 2.7151 - venom_accuracy: 0.8290 - venom_loss: 0.3939 - val_loss: 3.9312 - val_species_accuracy: 0.2090 - val_species_loss: 3.7345 - val_venom_accuracy: 0.8318 - val_venom_loss: 0.3907 - learning_rate: 5.0000e-04\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 1/40\n",
      "\u001b[1m1241/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12s\u001b[0m 87ms/step - loss: 2.6952 - species_accuracy: 0.2970 - species_loss: 2.7785 - venom_accuracy: 0.8307 - venom_loss: 0.3936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2.6938 - species_accuracy: 0.2971 - species_loss: 2.7770 - venom_accuracy: 0.8307 - venom_loss: 0.3935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:22:15.889051: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from None to 3.39254, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 135ms/step - loss: 2.6794 - species_accuracy: 0.2992 - species_loss: 2.7608 - venom_accuracy: 0.8309 - venom_loss: 0.3922 - val_loss: 3.3925 - val_species_accuracy: 0.2111 - val_species_loss: 3.6500 - val_venom_accuracy: 0.8312 - val_venom_loss: 0.3942\n",
      "Epoch 2/40\n",
      "\u001b[1m 269/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43\u001b[0m 93ms/step - loss: 2.6669 - species_accuracy: 0.3128 - species_loss: 2.7680 - venom_accuracy: 0.8400 - venom_loss: 0.3770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.6513 - species_accuracy: 0.3066 - species_loss: 2.7353 - venom_accuracy: 0.8327 - venom_loss: 0.3859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:26:06.015097: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 3.39254 to 3.38419, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 136ms/step - loss: 2.6394 - species_accuracy: 0.3048 - species_loss: 2.7134 - venom_accuracy: 0.8298 - venom_loss: 0.3908 - val_loss: 3.3842 - val_species_accuracy: 0.2134 - val_species_loss: 3.6393 - val_venom_accuracy: 0.8307 - val_venom_loss: 0.3937\n",
      "Epoch 3/40\n",
      "\u001b[1m 414/1385\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 89ms/step - loss: 2.6187 - species_accuracy: 0.3139 - species_loss: 2.6952 - venom_accuracy: 0.8303 - venom_loss: 0.3855"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.6139 - species_accuracy: 0.3134 - species_loss: 2.6859 - venom_accuracy: 0.8306 - venom_loss: 0.3877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:28:56.260968: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss improved from 3.38419 to 3.38030, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 136ms/step - loss: 2.6132 - species_accuracy: 0.3103 - species_loss: 2.6801 - venom_accuracy: 0.8301 - venom_loss: 0.3907 - val_loss: 3.3803 - val_species_accuracy: 0.2142 - val_species_loss: 3.6348 - val_venom_accuracy: 0.8312 - val_venom_loss: 0.3938\n",
      "Epoch 4/40\n",
      "\u001b[1m 313/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 89ms/step - loss: 2.6350 - species_accuracy: 0.3123 - species_loss: 2.6973 - venom_accuracy: 0.8248 - venom_loss: 0.3976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.6074 - species_accuracy: 0.3132 - species_loss: 2.6730 - venom_accuracy: 0.8294 - venom_loss: 0.3909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:32:06.033333: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_loss improved from 3.38030 to 3.37925, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5993 - species_accuracy: 0.3141 - species_loss: 2.6638 - venom_accuracy: 0.8302 - venom_loss: 0.3901 - val_loss: 3.3793 - val_species_accuracy: 0.2147 - val_species_loss: 3.6350 - val_venom_accuracy: 0.8315 - val_venom_loss: 0.3926\n",
      "Epoch 5/40\n",
      "\u001b[1m 317/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 90ms/step - loss: 2.6061 - species_accuracy: 0.3312 - species_loss: 2.6538 - venom_accuracy: 0.8191 - venom_loss: 0.4025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.6006 - species_accuracy: 0.3227 - species_loss: 2.6564 - venom_accuracy: 0.8263 - venom_loss: 0.3962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:35:21.401518: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: val_loss improved from 3.37925 to 3.37731, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.5880 - species_accuracy: 0.3191 - species_loss: 2.6483 - venom_accuracy: 0.8294 - venom_loss: 0.3911 - val_loss: 3.3773 - val_species_accuracy: 0.2160 - val_species_loss: 3.6324 - val_venom_accuracy: 0.8319 - val_venom_loss: 0.3932\n",
      "Epoch 6/40\n",
      "\u001b[1m 461/1385\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 93ms/step - loss: 2.5785 - species_accuracy: 0.2991 - species_loss: 2.6425 - venom_accuracy: 0.8284 - venom_loss: 0.3871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5863 - species_accuracy: 0.3061 - species_loss: 2.6496 - venom_accuracy: 0.8289 - venom_loss: 0.3889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:37:49.157761: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_loss improved from 3.37731 to 3.37513, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 137ms/step - loss: 2.5951 - species_accuracy: 0.3107 - species_loss: 2.6580 - venom_accuracy: 0.8288 - venom_loss: 0.3902 - val_loss: 3.3751 - val_species_accuracy: 0.2177 - val_species_loss: 3.6313 - val_venom_accuracy: 0.8321 - val_venom_loss: 0.3932\n",
      "Epoch 7/40\n",
      "\u001b[1m   7/1385\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 83ms/step - loss: 2.5009 - species_accuracy: 0.3397 - species_loss: 2.4802 - venom_accuracy: 0.8150 - venom_loss: 0.4306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.5713 - species_accuracy: 0.3197 - species_loss: 2.6260 - venom_accuracy: 0.8298 - venom_loss: 0.3921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:41:19.399912: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: val_loss improved from 3.37513 to 3.37276, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 131ms/step - loss: 2.5760 - species_accuracy: 0.3177 - species_loss: 2.6340 - venom_accuracy: 0.8303 - venom_loss: 0.3903 - val_loss: 3.3728 - val_species_accuracy: 0.2187 - val_species_loss: 3.6291 - val_venom_accuracy: 0.8321 - val_venom_loss: 0.3923\n",
      "Epoch 8/40\n",
      "\u001b[1m  92/1385\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43\u001b[0m 80ms/step - loss: 2.5452 - species_accuracy: 0.3202 - species_loss: 2.5955 - venom_accuracy: 0.8291 - venom_loss: 0.3907"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2.5563 - species_accuracy: 0.3176 - species_loss: 2.6113 - venom_accuracy: 0.8307 - venom_loss: 0.3894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:45:01.505836: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: val_loss did not improve from 3.37276\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 135ms/step - loss: 2.5607 - species_accuracy: 0.3192 - species_loss: 2.6184 - venom_accuracy: 0.8309 - venom_loss: 0.3885 - val_loss: 3.3737 - val_species_accuracy: 0.2188 - val_species_loss: 3.6279 - val_venom_accuracy: 0.8327 - val_venom_loss: 0.3927\n",
      "Epoch 9/40\n",
      "\u001b[1m1289/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - loss: 2.5852 - species_accuracy: 0.3191 - species_loss: 2.6461 - venom_accuracy: 0.8306 - venom_loss: 0.3903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5844 - species_accuracy: 0.3192 - species_loss: 2.6452 - venom_accuracy: 0.8306 - venom_loss: 0.3902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:47:55.225545: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: val_loss improved from 3.37276 to 3.37235, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5745 - species_accuracy: 0.3203 - species_loss: 2.6358 - venom_accuracy: 0.8303 - venom_loss: 0.3885 - val_loss: 3.3723 - val_species_accuracy: 0.2196 - val_species_loss: 3.6262 - val_venom_accuracy: 0.8324 - val_venom_loss: 0.3917\n",
      "Epoch 10/40\n",
      "\u001b[1m  48/1385\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 80ms/step - loss: 2.5685 - species_accuracy: 0.3240 - species_loss: 2.6272 - venom_accuracy: 0.8416 - venom_loss: 0.3890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5660 - species_accuracy: 0.3182 - species_loss: 2.6257 - venom_accuracy: 0.8314 - venom_loss: 0.3879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:50:53.665530: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: val_loss improved from 3.37235 to 3.37013, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 135ms/step - loss: 2.5653 - species_accuracy: 0.3193 - species_loss: 2.6219 - venom_accuracy: 0.8308 - venom_loss: 0.3897 - val_loss: 3.3701 - val_species_accuracy: 0.2202 - val_species_loss: 3.6243 - val_venom_accuracy: 0.8326 - val_venom_loss: 0.3923\n",
      "Epoch 11/40\n",
      "\u001b[1m1164/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - loss: 2.5409 - species_accuracy: 0.3189 - species_loss: 2.5899 - venom_accuracy: 0.8277 - venom_loss: 0.3908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5431 - species_accuracy: 0.3188 - species_loss: 2.5934 - venom_accuracy: 0.8281 - venom_loss: 0.3904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:54:08.105413: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: val_loss improved from 3.37013 to 3.36930, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 132ms/step - loss: 2.5548 - species_accuracy: 0.3188 - species_loss: 2.6102 - venom_accuracy: 0.8299 - venom_loss: 0.3887 - val_loss: 3.3693 - val_species_accuracy: 0.2202 - val_species_loss: 3.6251 - val_venom_accuracy: 0.8326 - val_venom_loss: 0.3916\n",
      "Epoch 12/40\n",
      "\u001b[1m 759/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 88ms/step - loss: 2.5309 - species_accuracy: 0.3225 - species_loss: 2.5777 - venom_accuracy: 0.8296 - venom_loss: 0.3906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5377 - species_accuracy: 0.3230 - species_loss: 2.5867 - venom_accuracy: 0.8297 - venom_loss: 0.3903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:57:08.156681: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: val_loss improved from 3.36930 to 3.36870, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.5490 - species_accuracy: 0.3231 - species_loss: 2.6045 - venom_accuracy: 0.8313 - venom_loss: 0.3877 - val_loss: 3.3687 - val_species_accuracy: 0.2200 - val_species_loss: 3.6227 - val_venom_accuracy: 0.8326 - val_venom_loss: 0.3916\n",
      "Epoch 13/40\n",
      "\u001b[1m1114/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m23s\u001b[0m 88ms/step - loss: 2.5348 - species_accuracy: 0.3242 - species_loss: 2.5926 - venom_accuracy: 0.8349 - venom_loss: 0.3839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5353 - species_accuracy: 0.3240 - species_loss: 2.5925 - venom_accuracy: 0.8345 - venom_loss: 0.3844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:00:24.596238: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: val_loss improved from 3.36870 to 3.36687, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5387 - species_accuracy: 0.3235 - species_loss: 2.5939 - venom_accuracy: 0.8330 - venom_loss: 0.3864 - val_loss: 3.3669 - val_species_accuracy: 0.2209 - val_species_loss: 3.6202 - val_venom_accuracy: 0.8328 - val_venom_loss: 0.3913\n",
      "Epoch 14/40\n",
      "\u001b[1m 555/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 91ms/step - loss: 2.5499 - species_accuracy: 0.3274 - species_loss: 2.6063 - venom_accuracy: 0.8318 - venom_loss: 0.3874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5545 - species_accuracy: 0.3238 - species_loss: 2.6131 - venom_accuracy: 0.8319 - venom_loss: 0.3867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:02:47.435968: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: val_loss improved from 3.36687 to 3.36455, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 151ms/step - loss: 2.5471 - species_accuracy: 0.3210 - species_loss: 2.6040 - venom_accuracy: 0.8313 - venom_loss: 0.3865 - val_loss: 3.3646 - val_species_accuracy: 0.2209 - val_species_loss: 3.6180 - val_venom_accuracy: 0.8331 - val_venom_loss: 0.3909\n",
      "Epoch 15/40\n",
      "\u001b[1m 971/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 88ms/step - loss: 2.5137 - species_accuracy: 0.3290 - species_loss: 2.5550 - venom_accuracy: 0.8300 - venom_loss: 0.3915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.5200 - species_accuracy: 0.3272 - species_loss: 2.5646 - venom_accuracy: 0.8305 - venom_loss: 0.3903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:06:42.569429: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: val_loss did not improve from 3.36455\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 135ms/step - loss: 2.5323 - species_accuracy: 0.3236 - species_loss: 2.5849 - venom_accuracy: 0.8322 - venom_loss: 0.3869 - val_loss: 3.3655 - val_species_accuracy: 0.2210 - val_species_loss: 3.6204 - val_venom_accuracy: 0.8330 - val_venom_loss: 0.3910\n",
      "Epoch 16/40\n",
      "\u001b[1m1251/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - loss: 2.5350 - species_accuracy: 0.3240 - species_loss: 2.5854 - venom_accuracy: 0.8301 - venom_loss: 0.3889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5353 - species_accuracy: 0.3240 - species_loss: 2.5862 - venom_accuracy: 0.8302 - venom_loss: 0.3886"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:09:10.896330: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: val_loss did not improve from 3.36455\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5368 - species_accuracy: 0.3246 - species_loss: 2.5921 - venom_accuracy: 0.8316 - venom_loss: 0.3858 - val_loss: 3.3656 - val_species_accuracy: 0.2214 - val_species_loss: 3.6196 - val_venom_accuracy: 0.8331 - val_venom_loss: 0.3923\n",
      "Epoch 17/40\n",
      "\u001b[1m1212/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - loss: 2.5306 - species_accuracy: 0.3228 - species_loss: 2.5806 - venom_accuracy: 0.8296 - venom_loss: 0.3884"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5306 - species_accuracy: 0.3228 - species_loss: 2.5813 - venom_accuracy: 0.8300 - venom_loss: 0.3880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:12:18.304671: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: val_loss improved from 3.36455 to 3.36239, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5316 - species_accuracy: 0.3228 - species_loss: 2.5862 - venom_accuracy: 0.8325 - venom_loss: 0.3854 - val_loss: 3.3624 - val_species_accuracy: 0.2212 - val_species_loss: 3.6142 - val_venom_accuracy: 0.8329 - val_venom_loss: 0.3912\n",
      "Epoch 18/40\n",
      "\u001b[1m 659/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 89ms/step - loss: 2.5515 - species_accuracy: 0.3165 - species_loss: 2.6110 - venom_accuracy: 0.8306 - venom_loss: 0.3856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5370 - species_accuracy: 0.3214 - species_loss: 2.5934 - venom_accuracy: 0.8310 - venom_loss: 0.3852\n",
      "Epoch 18: val_loss did not improve from 3.36239\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 136ms/step - loss: 2.5227 - species_accuracy: 0.3261 - species_loss: 2.5748 - venom_accuracy: 0.8320 - venom_loss: 0.3854 - val_loss: 3.3629 - val_species_accuracy: 0.2207 - val_species_loss: 3.6194 - val_venom_accuracy: 0.8332 - val_venom_loss: 0.3908\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:16:28.782837: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 895/1385\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 2.4979 - species_accuracy: 0.3281 - species_loss: 2.5514 - venom_accuracy: 0.8337 - venom_loss: 0.3806"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.5080 - species_accuracy: 0.3271 - species_loss: 2.5623 - venom_accuracy: 0.8334 - venom_loss: 0.3818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:18:44.869207: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: val_loss improved from 3.36239 to 3.36133, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 136ms/step - loss: 2.5286 - species_accuracy: 0.3250 - species_loss: 2.5806 - venom_accuracy: 0.8317 - venom_loss: 0.3865 - val_loss: 3.3613 - val_species_accuracy: 0.2220 - val_species_loss: 3.6175 - val_venom_accuracy: 0.8333 - val_venom_loss: 0.3904\n",
      "Epoch 20/40\n",
      "\u001b[1m1246/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12s\u001b[0m 86ms/step - loss: 2.5046 - species_accuracy: 0.3355 - species_loss: 2.5532 - venom_accuracy: 0.8306 - venom_loss: 0.3850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2.5056 - species_accuracy: 0.3350 - species_loss: 2.5547 - venom_accuracy: 0.8309 - venom_loss: 0.3849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:22:05.809066: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: val_loss improved from 3.36133 to 3.36004, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 133ms/step - loss: 2.5162 - species_accuracy: 0.3301 - species_loss: 2.5698 - venom_accuracy: 0.8329 - venom_loss: 0.3837 - val_loss: 3.3600 - val_species_accuracy: 0.2221 - val_species_loss: 3.6131 - val_venom_accuracy: 0.8331 - val_venom_loss: 0.3906\n",
      "Epoch 21/40\n",
      "\u001b[1m 819/1385\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 87ms/step - loss: 2.5240 - species_accuracy: 0.3273 - species_loss: 2.5788 - venom_accuracy: 0.8341 - venom_loss: 0.3841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5189 - species_accuracy: 0.3269 - species_loss: 2.5709 - venom_accuracy: 0.8331 - venom_loss: 0.3852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:25:45.389614: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: val_loss improved from 3.36004 to 3.35872, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 134ms/step - loss: 2.5229 - species_accuracy: 0.3251 - species_loss: 2.5720 - venom_accuracy: 0.8308 - venom_loss: 0.3877 - val_loss: 3.3587 - val_species_accuracy: 0.2229 - val_species_loss: 3.6140 - val_venom_accuracy: 0.8334 - val_venom_loss: 0.3900\n",
      "Epoch 22/40\n",
      "\u001b[1m  67/1385\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 80ms/step - loss: 2.5105 - species_accuracy: 0.3258 - species_loss: 2.5492 - venom_accuracy: 0.8220 - venom_loss: 0.3926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5191 - species_accuracy: 0.3256 - species_loss: 2.5661 - venom_accuracy: 0.8308 - venom_loss: 0.3886"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:28:07.208109: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: val_loss improved from 3.35872 to 3.35690, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 136ms/step - loss: 2.5229 - species_accuracy: 0.3276 - species_loss: 2.5749 - venom_accuracy: 0.8337 - venom_loss: 0.3860 - val_loss: 3.3569 - val_species_accuracy: 0.2232 - val_species_loss: 3.6093 - val_venom_accuracy: 0.8336 - val_venom_loss: 0.3911\n",
      "Epoch 23/40\n",
      "\u001b[1m1019/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - loss: 2.5094 - species_accuracy: 0.3276 - species_loss: 2.5608 - venom_accuracy: 0.8316 - venom_loss: 0.3840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5113 - species_accuracy: 0.3268 - species_loss: 2.5632 - venom_accuracy: 0.8316 - venom_loss: 0.3840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:31:02.136226: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: val_loss improved from 3.35690 to 3.35618, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 133ms/step - loss: 2.5167 - species_accuracy: 0.3258 - species_loss: 2.5685 - venom_accuracy: 0.8316 - venom_loss: 0.3847 - val_loss: 3.3562 - val_species_accuracy: 0.2227 - val_species_loss: 3.6099 - val_venom_accuracy: 0.8336 - val_venom_loss: 0.3903\n",
      "Epoch 24/40\n",
      "\u001b[1m 394/1385\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 88ms/step - loss: 2.5049 - species_accuracy: 0.3242 - species_loss: 2.5572 - venom_accuracy: 0.8339 - venom_loss: 0.3826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5002 - species_accuracy: 0.3300 - species_loss: 2.5484 - venom_accuracy: 0.8321 - venom_loss: 0.3846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:34:19.628415: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: val_loss improved from 3.35618 to 3.35587, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5086 - species_accuracy: 0.3306 - species_loss: 2.5548 - venom_accuracy: 0.8307 - venom_loss: 0.3873 - val_loss: 3.3559 - val_species_accuracy: 0.2229 - val_species_loss: 3.6081 - val_venom_accuracy: 0.8338 - val_venom_loss: 0.3909\n",
      "Epoch 25/40\n",
      "\u001b[1m1012/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 89ms/step - loss: 2.5037 - species_accuracy: 0.3272 - species_loss: 2.5600 - venom_accuracy: 0.8330 - venom_loss: 0.3797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5027 - species_accuracy: 0.3276 - species_loss: 2.5582 - venom_accuracy: 0.8329 - venom_loss: 0.3802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:37:20.899005: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: val_loss improved from 3.35587 to 3.35515, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 136ms/step - loss: 2.5047 - species_accuracy: 0.3288 - species_loss: 2.5548 - venom_accuracy: 0.8314 - venom_loss: 0.3840 - val_loss: 3.3551 - val_species_accuracy: 0.2226 - val_species_loss: 3.6095 - val_venom_accuracy: 0.8337 - val_venom_loss: 0.3908\n",
      "Epoch 26/40\n",
      "\u001b[1m 729/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 84ms/step - loss: 2.4980 - species_accuracy: 0.3297 - species_loss: 2.5454 - venom_accuracy: 0.8352 - venom_loss: 0.3847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4968 - species_accuracy: 0.3302 - species_loss: 2.5423 - venom_accuracy: 0.8337 - venom_loss: 0.3858"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:41:18.949576: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: val_loss improved from 3.35515 to 3.35452, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.4972 - species_accuracy: 0.3313 - species_loss: 2.5432 - venom_accuracy: 0.8321 - venom_loss: 0.3857 - val_loss: 3.3545 - val_species_accuracy: 0.2229 - val_species_loss: 3.6121 - val_venom_accuracy: 0.8340 - val_venom_loss: 0.3904\n",
      "Epoch 27/40\n",
      "\u001b[1m  88/1385\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 81ms/step - loss: 2.4821 - species_accuracy: 0.3253 - species_loss: 2.5430 - venom_accuracy: 0.8373 - venom_loss: 0.3731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.4833 - species_accuracy: 0.3309 - species_loss: 2.5360 - venom_accuracy: 0.8341 - venom_loss: 0.3788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:43:25.960598: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27: val_loss did not improve from 3.35452\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 136ms/step - loss: 2.4974 - species_accuracy: 0.3294 - species_loss: 2.5489 - venom_accuracy: 0.8337 - venom_loss: 0.3820 - val_loss: 3.3548 - val_species_accuracy: 0.2225 - val_species_loss: 3.6098 - val_venom_accuracy: 0.8335 - val_venom_loss: 0.3900\n",
      "Epoch 28/40\n",
      "\u001b[1m 725/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 87ms/step - loss: 2.4990 - species_accuracy: 0.3297 - species_loss: 2.5512 - venom_accuracy: 0.8332 - venom_loss: 0.3817"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4954 - species_accuracy: 0.3314 - species_loss: 2.5463 - venom_accuracy: 0.8333 - venom_loss: 0.3820"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:46:43.297130: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: val_loss improved from 3.35452 to 3.35313, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.4906 - species_accuracy: 0.3340 - species_loss: 2.5377 - venom_accuracy: 0.8326 - venom_loss: 0.3836 - val_loss: 3.3531 - val_species_accuracy: 0.2227 - val_species_loss: 3.6069 - val_venom_accuracy: 0.8340 - val_venom_loss: 0.3896\n",
      "Epoch 29/40\n",
      "\u001b[1m 540/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 85ms/step - loss: 2.4833 - species_accuracy: 0.3343 - species_loss: 2.5476 - venom_accuracy: 0.8403 - venom_loss: 0.3710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4817 - species_accuracy: 0.3345 - species_loss: 2.5364 - venom_accuracy: 0.8366 - venom_loss: 0.3772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:49:59.307465: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: val_loss improved from 3.35313 to 3.35238, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 136ms/step - loss: 2.4877 - species_accuracy: 0.3333 - species_loss: 2.5356 - venom_accuracy: 0.8330 - venom_loss: 0.3827 - val_loss: 3.3524 - val_species_accuracy: 0.2240 - val_species_loss: 3.6064 - val_venom_accuracy: 0.8339 - val_venom_loss: 0.3892\n",
      "Epoch 30/40\n",
      "\u001b[1m 251/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 93ms/step - loss: 2.4584 - species_accuracy: 0.3407 - species_loss: 2.5024 - venom_accuracy: 0.8326 - venom_loss: 0.3804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.4871 - species_accuracy: 0.3350 - species_loss: 2.5375 - venom_accuracy: 0.8333 - venom_loss: 0.3809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:52:52.012803: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: val_loss improved from 3.35238 to 3.35109, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 137ms/step - loss: 2.4917 - species_accuracy: 0.3329 - species_loss: 2.5395 - venom_accuracy: 0.8317 - venom_loss: 0.3835 - val_loss: 3.3511 - val_species_accuracy: 0.2238 - val_species_loss: 3.6052 - val_venom_accuracy: 0.8339 - val_venom_loss: 0.3890\n",
      "Epoch 31/40\n",
      "\u001b[1m 497/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16\u001b[0m 86ms/step - loss: 2.4703 - species_accuracy: 0.3388 - species_loss: 2.5186 - venom_accuracy: 0.8357 - venom_loss: 0.3795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4817 - species_accuracy: 0.3348 - species_loss: 2.5283 - venom_accuracy: 0.8347 - venom_loss: 0.3825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:56:53.322613: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: val_loss did not improve from 3.35109\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.4892 - species_accuracy: 0.3327 - species_loss: 2.5343 - venom_accuracy: 0.8335 - venom_loss: 0.3846 - val_loss: 3.3523 - val_species_accuracy: 0.2239 - val_species_loss: 3.6051 - val_venom_accuracy: 0.8340 - val_venom_loss: 0.3908\n",
      "Epoch 32/40\n",
      "\u001b[1m 852/1385\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 87ms/step - loss: 2.4818 - species_accuracy: 0.3336 - species_loss: 2.5377 - venom_accuracy: 0.8354 - venom_loss: 0.3763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4851 - species_accuracy: 0.3335 - species_loss: 2.5381 - venom_accuracy: 0.8345 - venom_loss: 0.3789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:59:23.560965: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: val_loss improved from 3.35109 to 3.35018, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.4878 - species_accuracy: 0.3330 - species_loss: 2.5336 - venom_accuracy: 0.8322 - venom_loss: 0.3840 - val_loss: 3.3502 - val_species_accuracy: 0.2238 - val_species_loss: 3.6039 - val_venom_accuracy: 0.8340 - val_venom_loss: 0.3899\n",
      "Epoch 33/40\n",
      "\u001b[1m 725/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 88ms/step - loss: 2.4884 - species_accuracy: 0.3359 - species_loss: 2.5330 - venom_accuracy: 0.8330 - venom_loss: 0.3850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.4868 - species_accuracy: 0.3340 - species_loss: 2.5304 - venom_accuracy: 0.8327 - venom_loss: 0.3854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:02:45.860913: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: val_loss did not improve from 3.35018\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.4836 - species_accuracy: 0.3331 - species_loss: 2.5268 - venom_accuracy: 0.8324 - venom_loss: 0.3850 - val_loss: 3.3504 - val_species_accuracy: 0.2235 - val_species_loss: 3.6028 - val_venom_accuracy: 0.8339 - val_venom_loss: 0.3897\n",
      "Epoch 34/40\n",
      "\u001b[1m 342/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 79ms/step - loss: 2.4841 - species_accuracy: 0.3404 - species_loss: 2.5297 - venom_accuracy: 0.8294 - venom_loss: 0.3836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4760 - species_accuracy: 0.3390 - species_loss: 2.5203 - venom_accuracy: 0.8323 - venom_loss: 0.3831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:06:20.441389: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: val_loss did not improve from 3.35018\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 134ms/step - loss: 2.4714 - species_accuracy: 0.3391 - species_loss: 2.5156 - venom_accuracy: 0.8328 - venom_loss: 0.3825 - val_loss: 3.3511 - val_species_accuracy: 0.2234 - val_species_loss: 3.6061 - val_venom_accuracy: 0.8337 - val_venom_loss: 0.3903\n",
      "Epoch 35/40\n",
      "\u001b[1m 769/1385\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 88ms/step - loss: 2.4790 - species_accuracy: 0.3417 - species_loss: 2.5283 - venom_accuracy: 0.8348 - venom_loss: 0.3803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4780 - species_accuracy: 0.3398 - species_loss: 2.5251 - venom_accuracy: 0.8347 - venom_loss: 0.3816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:08:59.780262: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35: val_loss improved from 3.35018 to 3.34887, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.4807 - species_accuracy: 0.3356 - species_loss: 2.5249 - venom_accuracy: 0.8338 - venom_loss: 0.3838 - val_loss: 3.3489 - val_species_accuracy: 0.2235 - val_species_loss: 3.6018 - val_venom_accuracy: 0.8340 - val_venom_loss: 0.3892\n",
      "Epoch 36/40\n",
      "\u001b[1m1228/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m13s\u001b[0m 88ms/step - loss: 2.4722 - species_accuracy: 0.3380 - species_loss: 2.5143 - venom_accuracy: 0.8316 - venom_loss: 0.3840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4722 - species_accuracy: 0.3377 - species_loss: 2.5145 - venom_accuracy: 0.8317 - venom_loss: 0.3838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:11:55.570148: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: val_loss improved from 3.34887 to 3.34832, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.4703 - species_accuracy: 0.3349 - species_loss: 2.5146 - venom_accuracy: 0.8334 - venom_loss: 0.3821 - val_loss: 3.3483 - val_species_accuracy: 0.2244 - val_species_loss: 3.6014 - val_venom_accuracy: 0.8341 - val_venom_loss: 0.3899\n",
      "Epoch 37/40\n",
      "\u001b[1m 279/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 92ms/step - loss: 2.4782 - species_accuracy: 0.3359 - species_loss: 2.5175 - venom_accuracy: 0.8317 - venom_loss: 0.3868"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.4766 - species_accuracy: 0.3351 - species_loss: 2.5191 - venom_accuracy: 0.8333 - venom_loss: 0.3845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:15:27.878747: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37: val_loss improved from 3.34832 to 3.34746, saving model to best_model_fold2_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.4691 - species_accuracy: 0.3362 - species_loss: 2.5128 - venom_accuracy: 0.8335 - venom_loss: 0.3822 - val_loss: 3.3475 - val_species_accuracy: 0.2236 - val_species_loss: 3.6005 - val_venom_accuracy: 0.8339 - val_venom_loss: 0.3895\n",
      "Epoch 38/40\n",
      "\u001b[1m1057/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 2.4476 - species_accuracy: 0.3428 - species_loss: 2.4916 - venom_accuracy: 0.8349 - venom_loss: 0.3786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.4496 - species_accuracy: 0.3422 - species_loss: 2.4937 - venom_accuracy: 0.8348 - venom_loss: 0.3789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:18:13.640670: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: val_loss did not improve from 3.34746\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 136ms/step - loss: 2.4564 - species_accuracy: 0.3397 - species_loss: 2.5013 - venom_accuracy: 0.8346 - venom_loss: 0.3792 - val_loss: 3.3487 - val_species_accuracy: 0.2238 - val_species_loss: 3.6008 - val_venom_accuracy: 0.8337 - val_venom_loss: 0.3898\n",
      "Epoch 39/40\n",
      "\u001b[1m 161/1385\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 100ms/step - loss: 2.3864 - species_accuracy: 0.3485 - species_loss: 2.4417 - venom_accuracy: 0.8468 - venom_loss: 0.3608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.4468 - species_accuracy: 0.3434 - species_loss: 2.4930 - venom_accuracy: 0.8369 - venom_loss: 0.3770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:21:40.601345: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39: val_loss did not improve from 3.34746\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.4636 - species_accuracy: 0.3410 - species_loss: 2.5067 - venom_accuracy: 0.8336 - venom_loss: 0.3819 - val_loss: 3.3492 - val_species_accuracy: 0.2233 - val_species_loss: 3.6034 - val_venom_accuracy: 0.8344 - val_venom_loss: 0.3891\n",
      "Epoch 40/40\n",
      "\u001b[1m 939/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 90ms/step - loss: 2.4648 - species_accuracy: 0.3388 - species_loss: 2.5023 - venom_accuracy: 0.8334 - venom_loss: 0.3858"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.4638 - species_accuracy: 0.3390 - species_loss: 2.5015 - venom_accuracy: 0.8333 - venom_loss: 0.3854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:24:06.739052: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: val_loss did not improve from 3.34746\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 137ms/step - loss: 2.4648 - species_accuracy: 0.3384 - species_loss: 2.5046 - venom_accuracy: 0.8333 - venom_loss: 0.3843 - val_loss: 3.3485 - val_species_accuracy: 0.2237 - val_species_loss: 3.5998 - val_venom_accuracy: 0.8341 - val_venom_loss: 0.3899\n",
      "Restoring model weights from the end of the best epoch: 37.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:25:19.580795: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n",
      "2025-12-04 05:25:53.573897: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Metrics ===\n",
      "1) Species accuracy: 0.2236\n",
      "2) Macro-averaged F1 (species): 0.2134\n",
      "3) Venom decision accuracy: 0.8339\n",
      "4) Venom-weighted species accuracy: 0.5010\n",
      "\n",
      "===== FOLD 3/3 =====\n",
      "Epoch 1/60\n",
      "\u001b[1m 329/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 89ms/step - loss: 5.8898 - species_accuracy: 0.0140 - species_loss: 5.6475 - venom_accuracy: 0.7973 - venom_loss: 0.4846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:26:29.751907: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 5.4815 - species_accuracy: 0.0349 - species_loss: 5.2499 - venom_accuracy: 0.8038 - venom_loss: 0.4632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from None to 4.35670, saving model to best_model_fold3.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 135ms/step - loss: 5.1076 - species_accuracy: 0.0558 - species_loss: 4.8832 - venom_accuracy: 0.8081 - venom_loss: 0.4488 - val_loss: 4.3567 - val_species_accuracy: 0.1269 - val_species_loss: 4.1523 - val_venom_accuracy: 0.8244 - val_venom_loss: 0.4079 - learning_rate: 5.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m 454/1385\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 95ms/step - loss: 4.3323 - species_accuracy: 0.1208 - species_loss: 4.1218 - venom_accuracy: 0.8198 - venom_loss: 0.4210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:29:50.859128: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4.3295 - species_accuracy: 0.1224 - species_loss: 4.1177 - venom_accuracy: 0.8177 - venom_loss: 0.4236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 4.35670 to 4.13691, saving model to best_model_fold3.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 137ms/step - loss: 4.3194 - species_accuracy: 0.1252 - species_loss: 4.1064 - venom_accuracy: 0.8160 - venom_loss: 0.4253 - val_loss: 4.1369 - val_species_accuracy: 0.1514 - val_species_loss: 3.9363 - val_venom_accuracy: 0.8238 - val_venom_loss: 0.4022 - learning_rate: 5.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m 172/1385\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 80ms/step - loss: 4.0323 - species_accuracy: 0.1577 - species_loss: 3.8197 - venom_accuracy: 0.8146 - venom_loss: 0.4252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:32:32.101487: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4.0083 - species_accuracy: 0.1586 - species_loss: 3.7971 - venom_accuracy: 0.8155 - venom_loss: 0.4225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss improved from 4.13691 to 4.03260, saving model to best_model_fold3.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 152ms/step - loss: 4.0156 - species_accuracy: 0.1576 - species_loss: 3.8059 - venom_accuracy: 0.8175 - venom_loss: 0.4198 - val_loss: 4.0326 - val_species_accuracy: 0.1724 - val_species_loss: 3.8310 - val_venom_accuracy: 0.8287 - val_venom_loss: 0.4041 - learning_rate: 5.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m1362/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 3.7757 - species_accuracy: 0.1908 - species_loss: 3.5697 - venom_accuracy: 0.8225 - venom_loss: 0.4120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:37:46.738370: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3.7760 - species_accuracy: 0.1907 - species_loss: 3.5700 - venom_accuracy: 0.8225 - venom_loss: 0.4121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_loss improved from 4.03260 to 3.93699, saving model to best_model_fold3.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 3.7936 - species_accuracy: 0.1875 - species_loss: 3.5869 - venom_accuracy: 0.8213 - venom_loss: 0.4138 - val_loss: 3.9370 - val_species_accuracy: 0.1828 - val_species_loss: 3.7370 - val_venom_accuracy: 0.8291 - val_venom_loss: 0.3975 - learning_rate: 5.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m  82/1385\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43\u001b[0m 79ms/step - loss: 3.6007 - species_accuracy: 0.2342 - species_loss: 3.3954 - venom_accuracy: 0.8081 - venom_loss: 0.4107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:39:01.549761: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 3.5776 - species_accuracy: 0.2103 - species_loss: 3.3733 - venom_accuracy: 0.8236 - venom_loss: 0.4086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: val_loss improved from 3.93699 to 3.92279, saving model to best_model_fold3.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 3.6199 - species_accuracy: 0.2056 - species_loss: 3.4149 - venom_accuracy: 0.8238 - venom_loss: 0.4099 - val_loss: 3.9228 - val_species_accuracy: 0.1911 - val_species_loss: 3.7239 - val_venom_accuracy: 0.8287 - val_venom_loss: 0.4003 - learning_rate: 5.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m1034/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 89ms/step - loss: 3.4111 - species_accuracy: 0.2319 - species_loss: 3.2089 - venom_accuracy: 0.8224 - venom_loss: 0.4044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:43:34.519664: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 3.4209 - species_accuracy: 0.2302 - species_loss: 3.2182 - venom_accuracy: 0.8223 - venom_loss: 0.4053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_loss did not improve from 3.92279\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 130ms/step - loss: 3.4587 - species_accuracy: 0.2250 - species_loss: 3.2552 - venom_accuracy: 0.8230 - venom_loss: 0.4071 - val_loss: 3.9361 - val_species_accuracy: 0.1895 - val_species_loss: 3.7388 - val_venom_accuracy: 0.8324 - val_venom_loss: 0.3976 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m 998/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 90ms/step - loss: 3.2882 - species_accuracy: 0.2488 - species_loss: 3.0893 - venom_accuracy: 0.8290 - venom_loss: 0.3977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:46:32.606567: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 3.2963 - species_accuracy: 0.2473 - species_loss: 3.0967 - venom_accuracy: 0.8283 - venom_loss: 0.3991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: val_loss improved from 3.92279 to 3.91704, saving model to best_model_fold3.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 133ms/step - loss: 3.3299 - species_accuracy: 0.2411 - species_loss: 3.1284 - venom_accuracy: 0.8258 - venom_loss: 0.4028 - val_loss: 3.9170 - val_species_accuracy: 0.1981 - val_species_loss: 3.7126 - val_venom_accuracy: 0.8304 - val_venom_loss: 0.4085 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m 717/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 89ms/step - loss: 3.1717 - species_accuracy: 0.2696 - species_loss: 2.9664 - venom_accuracy: 0.8234 - venom_loss: 0.4105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:49:11.649404: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 3.1852 - species_accuracy: 0.2660 - species_loss: 2.9818 - venom_accuracy: 0.8241 - venom_loss: 0.4068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: val_loss improved from 3.91704 to 3.88762, saving model to best_model_fold3.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 136ms/step - loss: 3.2173 - species_accuracy: 0.2590 - species_loss: 3.0167 - venom_accuracy: 0.8252 - venom_loss: 0.4011 - val_loss: 3.8876 - val_species_accuracy: 0.2057 - val_species_loss: 3.6895 - val_venom_accuracy: 0.8302 - val_venom_loss: 0.3964 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m 871/1385\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 87ms/step - loss: 3.0399 - species_accuracy: 0.2834 - species_loss: 2.8391 - venom_accuracy: 0.8254 - venom_loss: 0.4018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:52:32.623476: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 3.0574 - species_accuracy: 0.2801 - species_loss: 2.8569 - venom_accuracy: 0.8257 - venom_loss: 0.4009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: val_loss did not improve from 3.88762\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 3.1055 - species_accuracy: 0.2719 - species_loss: 2.9053 - venom_accuracy: 0.8260 - venom_loss: 0.4003 - val_loss: 3.9133 - val_species_accuracy: 0.2023 - val_species_loss: 3.7127 - val_venom_accuracy: 0.8298 - val_venom_loss: 0.4041 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m1292/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - loss: 2.9672 - species_accuracy: 0.2932 - species_loss: 2.7695 - venom_accuracy: 0.8305 - venom_loss: 0.3954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:56:15.187382: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.9710 - species_accuracy: 0.2926 - species_loss: 2.7733 - venom_accuracy: 0.8303 - venom_loss: 0.3955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: val_loss did not improve from 3.88762\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 3.0260 - species_accuracy: 0.2844 - species_loss: 2.8278 - venom_accuracy: 0.8277 - venom_loss: 0.3958 - val_loss: 3.9201 - val_species_accuracy: 0.2088 - val_species_loss: 3.7185 - val_venom_accuracy: 0.8317 - val_venom_loss: 0.4003 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m 442/1385\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 87ms/step - loss: 2.8101 - species_accuracy: 0.3164 - species_loss: 2.6142 - venom_accuracy: 0.8297 - venom_loss: 0.3918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:58:06.675251: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.8658 - species_accuracy: 0.3089 - species_loss: 2.6695 - venom_accuracy: 0.8292 - venom_loss: 0.3925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: val_loss did not improve from 3.88762\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.9309 - species_accuracy: 0.2979 - species_loss: 2.7338 - venom_accuracy: 0.8272 - venom_loss: 0.3946 - val_loss: 3.9298 - val_species_accuracy: 0.2111 - val_species_loss: 3.7257 - val_venom_accuracy: 0.8306 - val_venom_loss: 0.4100 - learning_rate: 5.0000e-04\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 1/40\n",
      "\u001b[1m 941/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 90ms/step - loss: 2.7019 - species_accuracy: 0.2930 - species_loss: 2.7817 - venom_accuracy: 0.8279 - venom_loss: 0.3971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:02:05.296928: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.7008 - species_accuracy: 0.2942 - species_loss: 2.7805 - venom_accuracy: 0.8280 - venom_loss: 0.3970"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from None to 3.39309, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 132ms/step - loss: 2.6929 - species_accuracy: 0.2974 - species_loss: 2.7696 - venom_accuracy: 0.8275 - venom_loss: 0.3975 - val_loss: 3.3931 - val_species_accuracy: 0.2141 - val_species_loss: 3.6446 - val_venom_accuracy: 0.8305 - val_venom_loss: 0.3970\n",
      "Epoch 2/40\n",
      "\u001b[1m 576/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 92ms/step - loss: 2.6566 - species_accuracy: 0.2996 - species_loss: 2.7214 - venom_accuracy: 0.8255 - venom_loss: 0.3996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:04:36.196282: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.6536 - species_accuracy: 0.3021 - species_loss: 2.7226 - venom_accuracy: 0.8273 - venom_loss: 0.3962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 3.39309 to 3.38501, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 138ms/step - loss: 2.6484 - species_accuracy: 0.3046 - species_loss: 2.7219 - venom_accuracy: 0.8288 - venom_loss: 0.3925 - val_loss: 3.3850 - val_species_accuracy: 0.2166 - val_species_loss: 3.6358 - val_venom_accuracy: 0.8313 - val_venom_loss: 0.3970\n",
      "Epoch 3/40\n",
      "\u001b[1m 874/1385\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 87ms/step - loss: 2.6074 - species_accuracy: 0.3076 - species_loss: 2.6731 - venom_accuracy: 0.8308 - venom_loss: 0.3908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:08:10.725290: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.6124 - species_accuracy: 0.3078 - species_loss: 2.6796 - venom_accuracy: 0.8306 - venom_loss: 0.3907"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss improved from 3.38501 to 3.38303, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.6232 - species_accuracy: 0.3080 - species_loss: 2.6929 - venom_accuracy: 0.8300 - venom_loss: 0.3909 - val_loss: 3.3830 - val_species_accuracy: 0.2184 - val_species_loss: 3.6314 - val_venom_accuracy: 0.8317 - val_venom_loss: 0.3973\n",
      "Epoch 4/40\n",
      "\u001b[1m 927/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 87ms/step - loss: 2.6342 - species_accuracy: 0.3067 - species_loss: 2.7048 - venom_accuracy: 0.8287 - venom_loss: 0.3920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:11:22.247810: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.6326 - species_accuracy: 0.3070 - species_loss: 2.7021 - venom_accuracy: 0.8289 - venom_loss: 0.3924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_loss improved from 3.38303 to 3.38197, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.6245 - species_accuracy: 0.3073 - species_loss: 2.6927 - venom_accuracy: 0.8302 - venom_loss: 0.3918 - val_loss: 3.3820 - val_species_accuracy: 0.2188 - val_species_loss: 3.6313 - val_venom_accuracy: 0.8325 - val_venom_loss: 0.3967\n",
      "Epoch 5/40\n",
      "\u001b[1m1278/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - loss: 2.6138 - species_accuracy: 0.3096 - species_loss: 2.6774 - venom_accuracy: 0.8290 - venom_loss: 0.3932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:15:00.970764: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.6124 - species_accuracy: 0.3097 - species_loss: 2.6760 - venom_accuracy: 0.8291 - venom_loss: 0.3930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: val_loss improved from 3.38197 to 3.38042, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.5951 - species_accuracy: 0.3119 - species_loss: 2.6593 - venom_accuracy: 0.8290 - venom_loss: 0.3900 - val_loss: 3.3804 - val_species_accuracy: 0.2200 - val_species_loss: 3.6326 - val_venom_accuracy: 0.8324 - val_venom_loss: 0.3960\n",
      "Epoch 6/40\n",
      "\u001b[1m 964/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 90ms/step - loss: 2.6084 - species_accuracy: 0.3142 - species_loss: 2.6726 - venom_accuracy: 0.8296 - venom_loss: 0.3920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:17:42.689442: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.6081 - species_accuracy: 0.3144 - species_loss: 2.6728 - venom_accuracy: 0.8299 - venom_loss: 0.3916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_loss improved from 3.38042 to 3.37907, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 133ms/step - loss: 2.5987 - species_accuracy: 0.3156 - species_loss: 2.6611 - venom_accuracy: 0.8301 - venom_loss: 0.3912 - val_loss: 3.3791 - val_species_accuracy: 0.2207 - val_species_loss: 3.6319 - val_venom_accuracy: 0.8325 - val_venom_loss: 0.3949\n",
      "Epoch 7/40\n",
      "\u001b[1m  27/1385\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 83ms/step - loss: 2.5144 - species_accuracy: 0.3632 - species_loss: 2.5937 - venom_accuracy: 0.8306 - venom_loss: 0.3662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:19:22.942498: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5862 - species_accuracy: 0.3209 - species_loss: 2.6522 - venom_accuracy: 0.8297 - venom_loss: 0.3870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: val_loss did not improve from 3.37907\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5889 - species_accuracy: 0.3161 - species_loss: 2.6543 - venom_accuracy: 0.8291 - venom_loss: 0.3880 - val_loss: 3.3794 - val_species_accuracy: 0.2206 - val_species_loss: 3.6314 - val_venom_accuracy: 0.8325 - val_venom_loss: 0.3963\n",
      "Epoch 8/40\n",
      "\u001b[1m 205/1385\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 79ms/step - loss: 2.5542 - species_accuracy: 0.3081 - species_loss: 2.6060 - venom_accuracy: 0.8283 - venom_loss: 0.3912"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:22:42.961008: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5729 - species_accuracy: 0.3165 - species_loss: 2.6312 - venom_accuracy: 0.8286 - venom_loss: 0.3899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: val_loss improved from 3.37907 to 3.37774, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 135ms/step - loss: 2.5861 - species_accuracy: 0.3165 - species_loss: 2.6499 - venom_accuracy: 0.8307 - venom_loss: 0.3885 - val_loss: 3.3777 - val_species_accuracy: 0.2203 - val_species_loss: 3.6278 - val_venom_accuracy: 0.8330 - val_venom_loss: 0.3957\n",
      "Epoch 9/40\n",
      "\u001b[1m  57/1385\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 79ms/step - loss: 2.7003 - species_accuracy: 0.2961 - species_loss: 2.7785 - venom_accuracy: 0.8287 - venom_loss: 0.3979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:25:38.898528: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5834 - species_accuracy: 0.3155 - species_loss: 2.6449 - venom_accuracy: 0.8314 - venom_loss: 0.3895"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: val_loss improved from 3.37774 to 3.37706, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 135ms/step - loss: 2.5769 - species_accuracy: 0.3180 - species_loss: 2.6381 - venom_accuracy: 0.8306 - venom_loss: 0.3889 - val_loss: 3.3771 - val_species_accuracy: 0.2209 - val_species_loss: 3.6301 - val_venom_accuracy: 0.8337 - val_venom_loss: 0.3962\n",
      "Epoch 10/40\n",
      "\u001b[1m 749/1385\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 89ms/step - loss: 2.5565 - species_accuracy: 0.3181 - species_loss: 2.6163 - venom_accuracy: 0.8301 - venom_loss: 0.3862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:29:48.565334: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.5609 - species_accuracy: 0.3184 - species_loss: 2.6210 - venom_accuracy: 0.8307 - venom_loss: 0.3868"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: val_loss improved from 3.37706 to 3.37413, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 137ms/step - loss: 2.5710 - species_accuracy: 0.3174 - species_loss: 2.6316 - venom_accuracy: 0.8313 - venom_loss: 0.3883 - val_loss: 3.3741 - val_species_accuracy: 0.2207 - val_species_loss: 3.6247 - val_venom_accuracy: 0.8337 - val_venom_loss: 0.3945\n",
      "Epoch 11/40\n",
      "\u001b[1m   8/1385\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 84ms/step - loss: 2.4586 - species_accuracy: 0.3148 - species_loss: 2.5402 - venom_accuracy: 0.8535 - venom_loss: 0.3553"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:31:52.904665: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5664 - species_accuracy: 0.3189 - species_loss: 2.6213 - venom_accuracy: 0.8291 - venom_loss: 0.3912"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: val_loss did not improve from 3.37413\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5592 - species_accuracy: 0.3217 - species_loss: 2.6178 - venom_accuracy: 0.8309 - venom_loss: 0.3877 - val_loss: 3.3753 - val_species_accuracy: 0.2211 - val_species_loss: 3.6294 - val_venom_accuracy: 0.8334 - val_venom_loss: 0.3948\n",
      "Epoch 12/40\n",
      "\u001b[1m 249/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 79ms/step - loss: 2.5571 - species_accuracy: 0.3205 - species_loss: 2.6207 - venom_accuracy: 0.8322 - venom_loss: 0.3838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:35:18.127380: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5552 - species_accuracy: 0.3212 - species_loss: 2.6165 - venom_accuracy: 0.8324 - venom_loss: 0.3850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: val_loss improved from 3.37413 to 3.37278, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.5640 - species_accuracy: 0.3205 - species_loss: 2.6227 - venom_accuracy: 0.8311 - venom_loss: 0.3884 - val_loss: 3.3728 - val_species_accuracy: 0.2213 - val_species_loss: 3.6233 - val_venom_accuracy: 0.8332 - val_venom_loss: 0.3944\n",
      "Epoch 13/40\n",
      "\u001b[1m1178/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - loss: 2.5561 - species_accuracy: 0.3262 - species_loss: 2.6138 - venom_accuracy: 0.8333 - venom_loss: 0.3876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:39:49.374270: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5577 - species_accuracy: 0.3258 - species_loss: 2.6156 - venom_accuracy: 0.8331 - venom_loss: 0.3877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: val_loss improved from 3.37278 to 3.37048, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 136ms/step - loss: 2.5624 - species_accuracy: 0.3229 - species_loss: 2.6210 - venom_accuracy: 0.8315 - venom_loss: 0.3881 - val_loss: 3.3705 - val_species_accuracy: 0.2215 - val_species_loss: 3.6200 - val_venom_accuracy: 0.8334 - val_venom_loss: 0.3951\n",
      "Epoch 14/40\n",
      "\u001b[1m1218/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14s\u001b[0m 88ms/step - loss: 2.5199 - species_accuracy: 0.3278 - species_loss: 2.5751 - venom_accuracy: 0.8338 - venom_loss: 0.3831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:43:00.349518: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5232 - species_accuracy: 0.3273 - species_loss: 2.5786 - venom_accuracy: 0.8334 - venom_loss: 0.3836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: val_loss improved from 3.37048 to 3.36878, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 137ms/step - loss: 2.5491 - species_accuracy: 0.3235 - species_loss: 2.6036 - venom_accuracy: 0.8303 - venom_loss: 0.3888 - val_loss: 3.3688 - val_species_accuracy: 0.2218 - val_species_loss: 3.6201 - val_venom_accuracy: 0.8334 - val_venom_loss: 0.3937\n",
      "Epoch 15/40\n",
      "\u001b[1m 628/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 85ms/step - loss: 2.5448 - species_accuracy: 0.3232 - species_loss: 2.6037 - venom_accuracy: 0.8357 - venom_loss: 0.3849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:45:16.957141: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5430 - species_accuracy: 0.3242 - species_loss: 2.6022 - venom_accuracy: 0.8347 - venom_loss: 0.3844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: val_loss did not improve from 3.36878\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5415 - species_accuracy: 0.3243 - species_loss: 2.5990 - venom_accuracy: 0.8327 - venom_loss: 0.3850 - val_loss: 3.3696 - val_species_accuracy: 0.2222 - val_species_loss: 3.6203 - val_venom_accuracy: 0.8338 - val_venom_loss: 0.3930\n",
      "Epoch 16/40\n",
      "\u001b[1m 346/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 89ms/step - loss: 2.5624 - species_accuracy: 0.3312 - species_loss: 2.6181 - venom_accuracy: 0.8283 - venom_loss: 0.3899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:48:00.925552: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5374 - species_accuracy: 0.3303 - species_loss: 2.5885 - venom_accuracy: 0.8297 - venom_loss: 0.3888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: val_loss did not improve from 3.36878\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 133ms/step - loss: 2.5338 - species_accuracy: 0.3278 - species_loss: 2.5861 - venom_accuracy: 0.8309 - venom_loss: 0.3875 - val_loss: 3.3695 - val_species_accuracy: 0.2224 - val_species_loss: 3.6194 - val_venom_accuracy: 0.8334 - val_venom_loss: 0.3946\n",
      "Epoch 17/40\n",
      "\u001b[1m1025/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - loss: 2.5241 - species_accuracy: 0.3262 - species_loss: 2.5714 - venom_accuracy: 0.8310 - venom_loss: 0.3891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:52:02.393519: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5251 - species_accuracy: 0.3259 - species_loss: 2.5733 - venom_accuracy: 0.8313 - venom_loss: 0.3887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: val_loss did not improve from 3.36878\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 131ms/step - loss: 2.5299 - species_accuracy: 0.3260 - species_loss: 2.5822 - venom_accuracy: 0.8326 - venom_loss: 0.3866 - val_loss: 3.3693 - val_species_accuracy: 0.2221 - val_species_loss: 3.6228 - val_venom_accuracy: 0.8336 - val_venom_loss: 0.3942\n",
      "Epoch 18/40\n",
      "\u001b[1m 337/1385\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 79ms/step - loss: 2.5075 - species_accuracy: 0.3282 - species_loss: 2.5536 - venom_accuracy: 0.8280 - venom_loss: 0.3872"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:54:02.426658: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.5264 - species_accuracy: 0.3258 - species_loss: 2.5809 - venom_accuracy: 0.8319 - venom_loss: 0.3848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: val_loss improved from 3.36878 to 3.36678, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 130ms/step - loss: 2.5389 - species_accuracy: 0.3237 - species_loss: 2.5952 - venom_accuracy: 0.8330 - venom_loss: 0.3856 - val_loss: 3.3668 - val_species_accuracy: 0.2227 - val_species_loss: 3.6173 - val_venom_accuracy: 0.8336 - val_venom_loss: 0.3940\n",
      "Epoch 19/40\n",
      "\u001b[1m 488/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 87ms/step - loss: 2.5167 - species_accuracy: 0.3329 - species_loss: 2.5512 - venom_accuracy: 0.8244 - venom_loss: 0.3965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 06:57:17.833781: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5236 - species_accuracy: 0.3301 - species_loss: 2.5698 - venom_accuracy: 0.8288 - venom_loss: 0.3898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: val_loss improved from 3.36678 to 3.36343, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.5361 - species_accuracy: 0.3251 - species_loss: 2.5885 - venom_accuracy: 0.8307 - venom_loss: 0.3878 - val_loss: 3.3634 - val_species_accuracy: 0.2232 - val_species_loss: 3.6138 - val_venom_accuracy: 0.8341 - val_venom_loss: 0.3931\n",
      "Epoch 20/40\n",
      "\u001b[1m1059/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m28s\u001b[0m 86ms/step - loss: 2.5158 - species_accuracy: 0.3333 - species_loss: 2.5718 - venom_accuracy: 0.8361 - venom_loss: 0.3820"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:01:13.940318: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5174 - species_accuracy: 0.3321 - species_loss: 2.5730 - venom_accuracy: 0.8352 - venom_loss: 0.3825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: val_loss did not improve from 3.36343\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5284 - species_accuracy: 0.3275 - species_loss: 2.5832 - venom_accuracy: 0.8318 - venom_loss: 0.3848 - val_loss: 3.3641 - val_species_accuracy: 0.2231 - val_species_loss: 3.6154 - val_venom_accuracy: 0.8335 - val_venom_loss: 0.3939\n",
      "Epoch 21/40\n",
      "\u001b[1m1266/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - loss: 2.5366 - species_accuracy: 0.3275 - species_loss: 2.5845 - venom_accuracy: 0.8307 - venom_loss: 0.3908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:04:39.433913: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5357 - species_accuracy: 0.3275 - species_loss: 2.5836 - venom_accuracy: 0.8308 - venom_loss: 0.3906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: val_loss did not improve from 3.36343\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 135ms/step - loss: 2.5267 - species_accuracy: 0.3269 - species_loss: 2.5765 - venom_accuracy: 0.8316 - venom_loss: 0.3877 - val_loss: 3.3638 - val_species_accuracy: 0.2225 - val_species_loss: 3.6142 - val_venom_accuracy: 0.8337 - val_venom_loss: 0.3942\n",
      "Epoch 22/40\n",
      "\u001b[1m 644/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 90ms/step - loss: 2.5214 - species_accuracy: 0.3279 - species_loss: 2.5723 - venom_accuracy: 0.8287 - venom_loss: 0.3863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:06:53.845241: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5172 - species_accuracy: 0.3289 - species_loss: 2.5671 - venom_accuracy: 0.8301 - venom_loss: 0.3862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: val_loss improved from 3.36343 to 3.36304, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 138ms/step - loss: 2.5197 - species_accuracy: 0.3283 - species_loss: 2.5706 - venom_accuracy: 0.8317 - venom_loss: 0.3859 - val_loss: 3.3630 - val_species_accuracy: 0.2229 - val_species_loss: 3.6139 - val_venom_accuracy: 0.8338 - val_venom_loss: 0.3932\n",
      "Epoch 23/40\n",
      "\u001b[1m 626/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 85ms/step - loss: 2.4995 - species_accuracy: 0.3297 - species_loss: 2.5419 - venom_accuracy: 0.8336 - venom_loss: 0.3883"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:09:59.668076: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5104 - species_accuracy: 0.3295 - species_loss: 2.5566 - venom_accuracy: 0.8329 - venom_loss: 0.3876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: val_loss did not improve from 3.36304\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.5216 - species_accuracy: 0.3272 - species_loss: 2.5726 - venom_accuracy: 0.8330 - venom_loss: 0.3864 - val_loss: 3.3634 - val_species_accuracy: 0.2236 - val_species_loss: 3.6137 - val_venom_accuracy: 0.8338 - val_venom_loss: 0.3936\n",
      "Epoch 24/40\n",
      "\u001b[1m 983/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 86ms/step - loss: 2.5161 - species_accuracy: 0.3298 - species_loss: 2.5666 - venom_accuracy: 0.8315 - venom_loss: 0.3857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:13:38.243687: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5164 - species_accuracy: 0.3300 - species_loss: 2.5670 - venom_accuracy: 0.8319 - venom_loss: 0.3856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: val_loss improved from 3.36304 to 3.36077, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.5210 - species_accuracy: 0.3309 - species_loss: 2.5717 - venom_accuracy: 0.8318 - venom_loss: 0.3864 - val_loss: 3.3608 - val_species_accuracy: 0.2235 - val_species_loss: 3.6134 - val_venom_accuracy: 0.8337 - val_venom_loss: 0.3921\n",
      "Epoch 25/40\n",
      "\u001b[1m 920/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 87ms/step - loss: 2.5379 - species_accuracy: 0.3364 - species_loss: 2.5896 - venom_accuracy: 0.8289 - venom_loss: 0.3885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:16:40.554155: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5270 - species_accuracy: 0.3362 - species_loss: 2.5767 - venom_accuracy: 0.8289 - venom_loss: 0.3880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: val_loss did not improve from 3.36077\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.5085 - species_accuracy: 0.3333 - species_loss: 2.5564 - venom_accuracy: 0.8297 - venom_loss: 0.3861 - val_loss: 3.3608 - val_species_accuracy: 0.2237 - val_species_loss: 3.6102 - val_venom_accuracy: 0.8338 - val_venom_loss: 0.3935\n",
      "Epoch 26/40\n",
      "\u001b[1m 465/1385\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 87ms/step - loss: 2.4959 - species_accuracy: 0.3316 - species_loss: 2.5400 - venom_accuracy: 0.8286 - venom_loss: 0.3866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:19:07.758422: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.5070 - species_accuracy: 0.3313 - species_loss: 2.5578 - venom_accuracy: 0.8321 - venom_loss: 0.3840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: val_loss improved from 3.36077 to 3.35818, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 137ms/step - loss: 2.5073 - species_accuracy: 0.3306 - species_loss: 2.5558 - venom_accuracy: 0.8320 - venom_loss: 0.3855 - val_loss: 3.3582 - val_species_accuracy: 0.2236 - val_species_loss: 3.6086 - val_venom_accuracy: 0.8337 - val_venom_loss: 0.3930\n",
      "Epoch 27/40\n",
      "\u001b[1m1099/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m24s\u001b[0m 86ms/step - loss: 2.5418 - species_accuracy: 0.3294 - species_loss: 2.5962 - venom_accuracy: 0.8307 - venom_loss: 0.3874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:23:11.837133: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5371 - species_accuracy: 0.3293 - species_loss: 2.5909 - venom_accuracy: 0.8310 - venom_loss: 0.3870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27: val_loss improved from 3.35818 to 3.35809, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 132ms/step - loss: 2.5191 - species_accuracy: 0.3295 - species_loss: 2.5707 - venom_accuracy: 0.8324 - venom_loss: 0.3856 - val_loss: 3.3581 - val_species_accuracy: 0.2241 - val_species_loss: 3.6087 - val_venom_accuracy: 0.8335 - val_venom_loss: 0.3921\n",
      "Epoch 28/40\n",
      "\u001b[1m 773/1385\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 88ms/step - loss: 2.5108 - species_accuracy: 0.3365 - species_loss: 2.5520 - venom_accuracy: 0.8288 - venom_loss: 0.3910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:25:49.405338: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5092 - species_accuracy: 0.3345 - species_loss: 2.5541 - venom_accuracy: 0.8310 - venom_loss: 0.3882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: val_loss did not improve from 3.35809\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 134ms/step - loss: 2.5074 - species_accuracy: 0.3316 - species_loss: 2.5563 - venom_accuracy: 0.8334 - venom_loss: 0.3852 - val_loss: 3.3586 - val_species_accuracy: 0.2240 - val_species_loss: 3.6083 - val_venom_accuracy: 0.8338 - val_venom_loss: 0.3930\n",
      "Epoch 29/40\n",
      "\u001b[1m 829/1385\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 88ms/step - loss: 2.5092 - species_accuracy: 0.3283 - species_loss: 2.5638 - venom_accuracy: 0.8341 - venom_loss: 0.3818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:28:59.968680: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.5035 - species_accuracy: 0.3291 - species_loss: 2.5551 - venom_accuracy: 0.8332 - venom_loss: 0.3828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: val_loss improved from 3.35809 to 3.35770, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.4993 - species_accuracy: 0.3308 - species_loss: 2.5473 - venom_accuracy: 0.8324 - venom_loss: 0.3844 - val_loss: 3.3577 - val_species_accuracy: 0.2244 - val_species_loss: 3.6090 - val_venom_accuracy: 0.8339 - val_venom_loss: 0.3926\n",
      "Epoch 30/40\n",
      "\u001b[1m 545/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 92ms/step - loss: 2.5057 - species_accuracy: 0.3277 - species_loss: 2.5557 - venom_accuracy: 0.8304 - venom_loss: 0.3843"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:31:44.757504: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.4979 - species_accuracy: 0.3314 - species_loss: 2.5464 - venom_accuracy: 0.8317 - venom_loss: 0.3840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: val_loss improved from 3.35770 to 3.35697, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.4965 - species_accuracy: 0.3344 - species_loss: 2.5420 - venom_accuracy: 0.8319 - venom_loss: 0.3857 - val_loss: 3.3570 - val_species_accuracy: 0.2245 - val_species_loss: 3.6078 - val_venom_accuracy: 0.8337 - val_venom_loss: 0.3919\n",
      "Epoch 31/40\n",
      "\u001b[1m1176/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18s\u001b[0m 90ms/step - loss: 2.4796 - species_accuracy: 0.3352 - species_loss: 2.5317 - venom_accuracy: 0.8346 - venom_loss: 0.3785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:35:47.068565: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.4818 - species_accuracy: 0.3351 - species_loss: 2.5332 - venom_accuracy: 0.8344 - venom_loss: 0.3793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: val_loss did not improve from 3.35697\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 136ms/step - loss: 2.4924 - species_accuracy: 0.3346 - species_loss: 2.5383 - venom_accuracy: 0.8326 - venom_loss: 0.3848 - val_loss: 3.3574 - val_species_accuracy: 0.2253 - val_species_loss: 3.6078 - val_venom_accuracy: 0.8338 - val_venom_loss: 0.3923\n",
      "Epoch 32/40\n",
      "\u001b[1m 230/1385\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 94ms/step - loss: 2.4716 - species_accuracy: 0.3333 - species_loss: 2.5360 - venom_accuracy: 0.8464 - venom_loss: 0.3690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:37:31.584214: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.4759 - species_accuracy: 0.3339 - species_loss: 2.5296 - venom_accuracy: 0.8379 - venom_loss: 0.3768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: val_loss improved from 3.35697 to 3.35559, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 131ms/step - loss: 2.4901 - species_accuracy: 0.3321 - species_loss: 2.5373 - venom_accuracy: 0.8339 - venom_loss: 0.3835 - val_loss: 3.3556 - val_species_accuracy: 0.2246 - val_species_loss: 3.6073 - val_venom_accuracy: 0.8334 - val_venom_loss: 0.3931\n",
      "Epoch 33/40\n",
      "\u001b[1m1374/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4624 - species_accuracy: 0.3374 - species_loss: 2.5110 - venom_accuracy: 0.8344 - venom_loss: 0.3780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:42:11.427985: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4625 - species_accuracy: 0.3374 - species_loss: 2.5111 - venom_accuracy: 0.8344 - venom_loss: 0.3780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: val_loss did not improve from 3.35559\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.4793 - species_accuracy: 0.3347 - species_loss: 2.5260 - venom_accuracy: 0.8319 - venom_loss: 0.3819 - val_loss: 3.3556 - val_species_accuracy: 0.2262 - val_species_loss: 3.6082 - val_venom_accuracy: 0.8333 - val_venom_loss: 0.3923\n",
      "Epoch 34/40\n",
      "\u001b[1m 582/1385\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 85ms/step - loss: 2.5072 - species_accuracy: 0.3315 - species_loss: 2.5558 - venom_accuracy: 0.8356 - venom_loss: 0.3855"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:44:08.052096: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4927 - species_accuracy: 0.3336 - species_loss: 2.5404 - venom_accuracy: 0.8356 - venom_loss: 0.3837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: val_loss did not improve from 3.35559\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 135ms/step - loss: 2.4804 - species_accuracy: 0.3345 - species_loss: 2.5250 - venom_accuracy: 0.8346 - venom_loss: 0.3837 - val_loss: 3.3556 - val_species_accuracy: 0.2254 - val_species_loss: 3.6056 - val_venom_accuracy: 0.8335 - val_venom_loss: 0.3922\n",
      "Epoch 35/40\n",
      "\u001b[1m 655/1385\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 90ms/step - loss: 2.5029 - species_accuracy: 0.3349 - species_loss: 2.5511 - venom_accuracy: 0.8319 - venom_loss: 0.3850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:47:24.467069: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.4932 - species_accuracy: 0.3347 - species_loss: 2.5411 - venom_accuracy: 0.8331 - venom_loss: 0.3836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35: val_loss improved from 3.35559 to 3.35410, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 138ms/step - loss: 2.4831 - species_accuracy: 0.3353 - species_loss: 2.5286 - venom_accuracy: 0.8324 - venom_loss: 0.3837 - val_loss: 3.3541 - val_species_accuracy: 0.2250 - val_species_loss: 3.6052 - val_venom_accuracy: 0.8336 - val_venom_loss: 0.3919\n",
      "Epoch 36/40\n",
      "\u001b[1m 903/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 2.4667 - species_accuracy: 0.3429 - species_loss: 2.5056 - venom_accuracy: 0.8306 - venom_loss: 0.3852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:50:55.214129: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4705 - species_accuracy: 0.3408 - species_loss: 2.5108 - venom_accuracy: 0.8316 - venom_loss: 0.3849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: val_loss did not improve from 3.35410\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 135ms/step - loss: 2.4803 - species_accuracy: 0.3366 - species_loss: 2.5246 - venom_accuracy: 0.8334 - venom_loss: 0.3840 - val_loss: 3.3546 - val_species_accuracy: 0.2244 - val_species_loss: 3.6066 - val_venom_accuracy: 0.8338 - val_venom_loss: 0.3920\n",
      "Epoch 37/40\n",
      "\u001b[1m 801/1385\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 88ms/step - loss: 2.4694 - species_accuracy: 0.3387 - species_loss: 2.5213 - venom_accuracy: 0.8359 - venom_loss: 0.3770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:53:53.495771: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4731 - species_accuracy: 0.3382 - species_loss: 2.5214 - venom_accuracy: 0.8343 - venom_loss: 0.3800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37: val_loss improved from 3.35410 to 3.35409, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 135ms/step - loss: 2.4789 - species_accuracy: 0.3371 - species_loss: 2.5227 - venom_accuracy: 0.8320 - venom_loss: 0.3841 - val_loss: 3.3541 - val_species_accuracy: 0.2257 - val_species_loss: 3.6058 - val_venom_accuracy: 0.8338 - val_venom_loss: 0.3924\n",
      "Epoch 38/40\n",
      "\u001b[1m 832/1385\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 88ms/step - loss: 2.4688 - species_accuracy: 0.3411 - species_loss: 2.5079 - venom_accuracy: 0.8302 - venom_loss: 0.3854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 07:57:03.562809: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4701 - species_accuracy: 0.3410 - species_loss: 2.5108 - venom_accuracy: 0.8310 - venom_loss: 0.3846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: val_loss did not improve from 3.35409\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 135ms/step - loss: 2.4705 - species_accuracy: 0.3404 - species_loss: 2.5134 - venom_accuracy: 0.8324 - venom_loss: 0.3831 - val_loss: 3.3545 - val_species_accuracy: 0.2262 - val_species_loss: 3.6043 - val_venom_accuracy: 0.8336 - val_venom_loss: 0.3923\n",
      "Epoch 39/40\n",
      "\u001b[1m1239/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12s\u001b[0m 88ms/step - loss: 2.4622 - species_accuracy: 0.3324 - species_loss: 2.5125 - venom_accuracy: 0.8354 - venom_loss: 0.3768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 08:00:47.400914: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1384/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.4631 - species_accuracy: 0.3326 - species_loss: 2.5130 - venom_accuracy: 0.8352 - venom_loss: 0.3772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39: val_loss improved from 3.35409 to 3.35139, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 138ms/step - loss: 2.4713 - species_accuracy: 0.3348 - species_loss: 2.5166 - venom_accuracy: 0.8332 - venom_loss: 0.3816 - val_loss: 3.3514 - val_species_accuracy: 0.2258 - val_species_loss: 3.6018 - val_venom_accuracy: 0.8337 - val_venom_loss: 0.3918\n",
      "Epoch 40/40\n",
      "\u001b[1m 538/1385\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 86ms/step - loss: 2.4600 - species_accuracy: 0.3419 - species_loss: 2.5031 - venom_accuracy: 0.8352 - venom_loss: 0.3813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 08:02:55.574645: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.4605 - species_accuracy: 0.3420 - species_loss: 2.5033 - venom_accuracy: 0.8339 - venom_loss: 0.3815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: val_loss improved from 3.35139 to 3.34950, saving model to best_model_fold3_finetuned.keras\n",
      "\u001b[1m1385/1385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 136ms/step - loss: 2.4646 - species_accuracy: 0.3382 - species_loss: 2.5083 - venom_accuracy: 0.8335 - venom_loss: 0.3819 - val_loss: 3.3495 - val_species_accuracy: 0.2263 - val_species_loss: 3.5990 - val_venom_accuracy: 0.8334 - val_venom_loss: 0.3922\n",
      "Restoring model weights from the end of the best epoch: 40.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 558 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Metrics ===\n",
      "1) Species accuracy: 0.2263\n",
      "2) Macro-averaged F1 (species): 0.2174\n",
      "3) Venom decision accuracy: 0.8334\n",
      "4) Venom-weighted species accuracy: 0.5038\n"
     ]
    }
   ],
   "source": [
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_paths, y_species), start=1):\n",
    "    print(f\"\\n===== FOLD {fold_idx}/{NUM_FOLDS} =====\")\n",
    "\n",
    "    train_info = image_metadata.iloc[train_idx].copy()\n",
    "    val_info   = image_metadata.iloc[val_idx].copy()\n",
    "\n",
    "    # --- class weight csak a trainre számolva ---\n",
    "    species_classes = np.unique(train_info[\"encoded_id\"])\n",
    "    species_cw = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=species_classes,\n",
    "        y=train_info[\"encoded_id\"],\n",
    "    )\n",
    "    species_cw_dict = {int(c): w for c, w in zip(species_classes, species_cw)}\n",
    "\n",
    "    species_weight_vec = tf.constant(\n",
    "        [species_cw_dict[i] for i in range(len(species_cw_dict))],\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "\n",
    "    # --- tf.data datasetek ---\n",
    "    train_dataset = make_batches(\n",
    "        train_info,\n",
    "        IMAGE_RESOLUTION,\n",
    "        species_weight_vec=species_weight_vec,\n",
    "    )\n",
    "\n",
    "    val_dataset = make_batches(\n",
    "        val_info,\n",
    "        IMAGE_RESOLUTION,\n",
    "        species_weight_vec=None,\n",
    "    )\n",
    "\n",
    "    # --- modell: minden foldban újraépítjük ---\n",
    "    model = build_multitask_model(\n",
    "        num_species=NUM_SPECIES,\n",
    "        image_resolution=IMAGE_RESOLUTION,\n",
    "    )\n",
    "\n",
    "    lr = 5e-4  # EfficientNetB0-hoz alacsony LR\n",
    "\n",
    "    #stage 1: backbone freeze\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss={\n",
    "            \"species\": \"sparse_categorical_crossentropy\", \n",
    "            \"venom\": \"binary_crossentropy\"\n",
    "        },\n",
    "        loss_weights={\"species\": 1.0, \"venom\": 0.5},\n",
    "        metrics={\n",
    "            \"species\": \"accuracy\", \n",
    "            \"venom\": \"accuracy\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # --- callbackek fold-specifikus checkpointtal ---\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "        f\"best_model_fold{fold_idx}.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    reduce_lr_cb = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.3,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1,\n",
    "    )\n",
    "    n_epochs = 60\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=n_epochs,\n",
    "        callbacks=[checkpoint_cb, early_stop_cb, reduce_lr_cb],\n",
    "    )\n",
    "    #stage 2: unfreeze backbone\n",
    "    model.trainable = True\n",
    "    fine_tune_lr = 1e-5 #ehhez érdemes kisebb LR-t használni\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "        loss={\n",
    "            \"species\": \"sparse_categorical_crossentropy\", \n",
    "            \"venom\": \"binary_crossentropy\"                \n",
    "        },\n",
    "        loss_weights={\"species\": 0.8, \"venom\": 1.2},\n",
    "        metrics={\n",
    "            \"species\": \"accuracy\", \n",
    "            \"venom\": \"accuracy\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    ft_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "        f\"best_model_fold{fold_idx}_finetuned.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1,\n",
    "    )\n",
    "    ft_early_stop_cb = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=4,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "    \n",
    "    history_fine = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=40, \n",
    "        callbacks=[ft_checkpoint_cb, ft_early_stop_cb],\n",
    "    )\n",
    "\n",
    "   \n",
    "\n",
    "    # --- saját metrikák foldonként, get_scores-szal ---\n",
    "    metrics_fold = get_scores(\n",
    "        model,\n",
    "        image_metadata=image_metadata,\n",
    "        test_dataset=val_dataset,\n",
    "        venom_threshold=0.5,\n",
    "    )\n",
    "\n",
    "    fold_metrics.append(metrics_fold)\n",
    "\n",
    "    if metrics_fold[\"macro_f1\"] > best_macro_f1:\n",
    "        best_macro_f1 = metrics_fold[\"macro_f1\"]\n",
    "        best_fold_idx = fold_idx\n",
    "\n",
    "    \n",
    "    all_y_species_true.append(metrics_fold[\"y_species_true\"])\n",
    "    all_y_species_pred.append(metrics_fold[\"y_species_pred\"])\n",
    "    all_y_venom_true.append(metrics_fold[\"y_venom_true\"])\n",
    "    all_y_venom_pred.append(metrics_fold[\"y_venom_pred\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mloss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SoftF1Loss\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# --- aggregált CV-eredmények (átlag metrikák + összesített predikciók) ---\u001b[39;00m\n\u001b[32m      5\u001b[39m best_model = keras.models.load_model(\n\u001b[32m      6\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbest_model_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_fold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     custom_objects={\u001b[33m\"\u001b[39m\u001b[33mSoftF1Loss\u001b[39m\u001b[33m\"\u001b[39m: SoftF1Loss},\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'loss'"
     ]
    }
   ],
   "source": [
    "from loss import SoftF1Loss\n",
    "\n",
    "# --- aggregált CV-eredmények (átlag metrikák + összesített predikciók) ---\n",
    "\n",
    "best_model = keras.models.load_model(\n",
    "    f\"best_model_fold{best_fold_idx}.keras\",\n",
    "    custom_objects={\"SoftF1Loss\": SoftF1Loss},\n",
    ")\n",
    "best_model.save(\"final_cv_model.keras\")\n",
    "\n",
    "results_own_metrics = {\n",
    "    \"species_accuracy\": np.mean([m[\"species_accuracy\"] for m in fold_metrics]),\n",
    "    \"macro_f1\": np.mean([m[\"macro_f1\"] for m in fold_metrics]),\n",
    "    \"venom_accuracy\": np.mean([m[\"venom_accuracy\"] for m in fold_metrics]),\n",
    "    \"venom_weighted_species_accuracy\": np.mean(\n",
    "        [m[\"venom_weighted_species_accuracy\"] for m in fold_metrics]\n",
    "    ),\n",
    "    \"y_species_true\": np.concatenate(all_y_species_true, axis=0),\n",
    "    \"y_species_pred\": np.concatenate(all_y_species_pred, axis=0),\n",
    "    \"y_venom_true\": np.concatenate(all_y_venom_true, axis=0),\n",
    "    \"y_venom_pred\": np.concatenate(all_y_venom_pred, axis=0),\n",
    "}\n",
    "\n",
    "print(\"\\n=== Átlagolt keresztvalidációs eredmények ===\")\n",
    "print(f\"Species accuracy (val): {results_own_metrics['species_accuracy']:.4f}\")\n",
    "print(f\"Macro-F1 (species, val): {results_own_metrics['macro_f1']:.4f}\")\n",
    "print(f\"Venom accuracy (val): {results_own_metrics['venom_accuracy']:.4f}\")\n",
    "print(\n",
    "    \"Venom-weighted species accuracy (val): \"\n",
    "    f\"{results_own_metrics['venom_weighted_species_accuracy']:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_results_from_dataset(model, val_dataset, species_metadata, n_examples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Calculating scoring metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Function to tell if the species is venomous or not, based on encoded_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Plotting mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_per_class_recall_f1(results):\n",
    "    y_true = results[\"y_species_true\"]\n",
    "    y_pred = results[\"y_species_pred\"]\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    class_ids = sorted([int(c) for c in report.keys() if c.isdigit()])\n",
    "\n",
    "    recalls = [report[str(c)][\"recall\"] for c in class_ids]\n",
    "    f1s     = [report[str(c)][\"f1-score\"] for c in class_ids]\n",
    "\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.bar(class_ids, recalls)\n",
    "    plt.title(\"Per-Class Recall\")\n",
    "    plt.xlabel(\"Class ID\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.bar(class_ids, f1s)\n",
    "    plt.title(\"Per-Class F1-Score\")\n",
    "    plt.xlabel(\"Class ID\")\n",
    "    plt.ylabel(\"F1\")\n",
    "    plt.show()\n",
    "import numpy as np\n",
    "\n",
    "def get_top_confused_pairs(cm, species_names, top_k=20):\n",
    "    \"\"\"\n",
    "    Returns the top most confused class pairs from a confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        cm: confusion matrix (shape NxN)\n",
    "        species_names: list mapping class_id -> species name\n",
    "        top_k: how many confused pairs to return\n",
    "\n",
    "    Returns:\n",
    "        A list of dicts with:\n",
    "            true_id, pred_id, true_name, pred_name, count\n",
    "    \"\"\"\n",
    "    cm_no_diag = cm.copy()\n",
    "    np.fill_diagonal(cm_no_diag, 0)  # remove correct predictions\n",
    "\n",
    "    confusions = []\n",
    "\n",
    "    # Find all non-zero misclassifications\n",
    "    for true_cls in range(cm_no_diag.shape[0]):\n",
    "        for pred_cls in range(cm_no_diag.shape[1]):\n",
    "            count = cm_no_diag[true_cls, pred_cls]\n",
    "            if count > 0:\n",
    "                confusions.append((true_cls, pred_cls, count))\n",
    "\n",
    "    # Sort by count descending\n",
    "    confusions.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Build output list\n",
    "    results = []\n",
    "    for true_id, pred_id, count in confusions[:top_k]:\n",
    "        results.append({\n",
    "            \"true_id\": true_id,\n",
    "            \"pred_id\": pred_id,\n",
    "            \"true_name\": species_names[true_id],\n",
    "            \"pred_name\": species_names[pred_id],\n",
    "            \"count\": count\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(results):\n",
    "    y_true = results[\"y_species_true\"]\n",
    "    y_pred = results[\"y_species_pred\"]\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, cmap='Blues')\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_per_class_recall_f1(results_own_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(results_own_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
