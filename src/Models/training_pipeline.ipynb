{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Library imports, setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_metadata, visualize_data, make_dataset\n",
    "from model import build_cnn\n",
    "from score_metrics import get_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7956,
     "status": "ok",
     "timestamp": 1760103668680,
     "user": {
      "displayName": "Avarka",
      "userId": "01376155912533068519"
     },
     "user_tz": -120
    },
    "id": "cb7d91df",
    "outputId": "632fa06d-510c-411c-bd31-1a43c8eb8343"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check tf version\n",
    "print(tf.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for device in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "    print(f\"Found GPU {device.name}, and set memory growth to True.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_metadata, species_metadata = load_metadata()\n",
    "num_classes = len(species_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in data.py\n",
    "visualize_data(image_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "d98e31d7"
   },
   "source": [
    "Loading python images from folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_RESOLUTION=28\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = make_dataset(image_metadata, IMAGE_RESOLUTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_cnn(num_classes, IMAGE_RESOLUTION)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    \n",
    "    loss={'species': 'sparse_categorical_crossentropy',\n",
    "          'venom': 'binary_crossentropy'},\n",
    "\n",
    "    metrics={'species': 'accuracy',\n",
    "             'venom': 'accuracy'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10 \n",
    "\n",
    "# checkpointing based on the validation loss\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('model.keras', monitor='val_loss', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "\n",
    "# model training\n",
    "model_history = model.fit(\n",
    "                            x= train_dataset,\n",
    "                            epochs= n_epochs,\n",
    "                            validation_data= val_dataset,\n",
    "                            callbacks=[model_checkpoint_callback])\n",
    "\n",
    "model.load_weights('model.keras')  # load weights back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history = model.evaluate(test_dataset)\n",
    "print(\"Test Loss: \", test_history[0])\n",
    "print(\"Test Accuracy: \", test_history[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def example_results_from_dataset(model, ds, species_names, n_examples=5, venom_threshold=0.5):\n",
    "    \"\"\"\n",
    "    ds must yield: (image, {'species': int, 'venom': int})\n",
    "    species_names: list where index == encoded_id\n",
    "    \"\"\"\n",
    "    # unbatch to individual samples and take a few\n",
    "    samples = list(ds.unbatch().take(n_examples))\n",
    "    imgs = [x[0] for x in samples]\n",
    "    lbls = [x[1] for x in samples]\n",
    "\n",
    "    # stack to a batch for one predict()\n",
    "    x_batch = tf.stack(imgs, axis=0)\n",
    "    pred_species_logits, pred_venom_prob = model.predict(x_batch, verbose=0)\n",
    "\n",
    "    plt.figure(figsize=(3.3 * len(imgs), 3.3))\n",
    "    for i, (img, y) in enumerate(zip(imgs, lbls), start=1):\n",
    "        true_species = int(y[\"species\"].numpy())\n",
    "        true_venom   = int(y[\"venom\"].numpy())\n",
    "\n",
    "        pred_species = int(np.argmax(pred_species_logits[i-1]))\n",
    "        pred_venom   = bool(float(pred_venom_prob[i-1][0]) > venom_threshold)\n",
    "\n",
    "        true_name = species_names[true_species] if 0 <= true_species < len(species_names) else str(true_species)\n",
    "        pred_name = species_names[pred_species] if 0 <= pred_species < len(species_names) else str(pred_species)\n",
    "\n",
    "        plt.subplot(1, len(imgs), i)\n",
    "        plt.imshow(img.numpy())\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\n",
    "            f\"True: {true_name} ({'Venom' if true_venom else 'Safe'})\\n\"\n",
    "            f\"Pred: {pred_name} ({'Venom' if pred_venom else 'Safe'})\",\n",
    "            fontsize=9\n",
    "        )\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_results_from_dataset(model, test_dataset, species_metadata, n_examples=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Calculating scoring metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Function to tell if the species is venomous or not, based on encoded_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(model, image_metadata, test_dataset, venom_threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
